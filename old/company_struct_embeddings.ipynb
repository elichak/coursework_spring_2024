{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6462f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "get_ipython().run_line_magic('autoreload', '2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1da05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import *\n",
    "from networkx.readwrite.json_graph import node_link_graph\n",
    "tqdm.pandas()\n",
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c98b2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.sage import SAGE\n",
    "from models.loss import DotCeLossWithOkvedDistances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6dc713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrained_embedding_tensor(idx_to_okved: dict, path_to_embeddings_dict: str) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Создает тензор с эмбеддингами ОКВЭД\n",
    "\n",
    "    Args:\n",
    "        idx_to_okved (dict): маппинг номер кода ОКВЭД - код\n",
    "        path_to_embeddings_dict: путь с словарю с эмбеддингами ОКВЭД\n",
    "    Returns:\n",
    "        torch.Tensor: тензор с эмбеддингами ОКВЭД\n",
    "    \"\"\"\n",
    "    with open(path_to_embeddings_dict, 'rb') as fp:\n",
    "        embeddings_dict = pickle.load(fp)\n",
    "        embedding_size = len(next(iter(embeddings_dict.values())))\n",
    "        embedding_tensor = torch.zeros(len(idx_to_okved), embedding_size)\n",
    "    for idx, okved in idx_to_okved.items():\n",
    "        if okved in embeddings_dict:\n",
    "            embedding_tensor[idx] = torch.FloatTensor(embeddings_dict[okved])\n",
    "    return embedding_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9732a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset_dir: str, result_dir: str, etypes=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Обрабатывает все файлы из каталога и подгатавливает датасет\n",
    "\n",
    "    Args:\n",
    "        dataset_dir (str): путь к каталогу с pickle файлами с информацией о ГСК\n",
    "        result_dir (str): путь для сохранения датасета\n",
    "        etypes (list, optional): список типов узлов для добавления в датасет\n",
    "    Returns:\n",
    "        list: датасет для решения задачи классификации ребер как находящихся внутри ГСК или ведущих вовне ГСК\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    dataset = []\n",
    "    for fname in tqdm(list(Path(dataset_dir).iterdir())):\n",
    "        with open(fname, 'rb') as fp:\n",
    "            data = pickle.load(fp)\n",
    "        node_membership = {}\n",
    "\n",
    "        data['nodes'] = [node for node in data['nodes'] if node['okved code'] != 'unknown']\n",
    "\n",
    "        # атрибуты узлов - номер кода ОКВЭД, финансовые показатели, ID компании\n",
    "        # оставляем только членов ГСК\n",
    "        for node in data['nodes']:\n",
    "            node['okved_code'] = okved_to_idx[node['okved_code']]\n",
    "            node['profit'] = np.array([node[k] for k in ['p21103', 'p21104']])\n",
    "            node['company_id'] = node['id']\n",
    "            node['gc_root'] = data['graph']['root']\n",
    "            node_membership[node['id']] = node['входит_в_ГСК']\n",
    "\n",
    "        # убираем ребра для удаленных узлов\n",
    "        data['links'] = [link for link in data['links'] if (link['source'] in node_membership and\n",
    "                                                            link['target'] in node_membership)]\n",
    "\n",
    "        for edge in data['links']:\n",
    "            edge['gc_root'] = data['graph']['root']\n",
    "            # 1 если оба узла входят в ГСК, 0 - если хотя бы один не входит\n",
    "            edge['label'] = int(node_membership[edge['source']] and node_membership[edge['target']])\n",
    "\n",
    "        # фильтруем типы связей\n",
    "        if etypes is not None:\n",
    "            data['links'] = [edge for edge in data['links'] if edge['key'] in etypes]\n",
    "        if not data['links'] or not data['nodes']:\n",
    "            continue\n",
    "\n",
    "        H = node_link_graph(data, directed=True, multigraph=False)\n",
    "        # убираем изолированные узлы, появившиеся в результате удаления других узлов или связей\n",
    "        H.remove_nodes_from(list(nx.isolates(H)))\n",
    "        if 'root' not in H.graph and 'ГСK_root' in data:\n",
    "            H.graph['root'] = data['ГСК_root']\n",
    "        g = dgl.from_networkx(H,\n",
    "                              node_attrs=['profit', 'okved_code', 'company_id', 'входит_в_ГСК', 'gc_root'],\n",
    "                              edge_attrs=['label'])\n",
    "\n",
    "        in_deg = g.in_degrees().view(-1, 1)\n",
    "        out_deg = g.out_degrees().view(-1, 1)\n",
    "        raw_profit = g.ndata['profit']\n",
    "\n",
    "        # вместо абсолютных значений берем знак raw_profit\n",
    "        profit = torch.where(raw_profit < 0, 0,\n",
    "                             torch.where(raw_profit == 0, 1, 2))\n",
    "        g.ndata['feats'] = torch.cat([profit.view(-1, 2),\n",
    "                                      in_deg,\n",
    "                                      out_deg], dim=1)\n",
    "\n",
    "        # 80% на обучение\n",
    "        g.edata['train_mask'] = torch.zeros(g.num_edges(), dtype=torch.bool).bernoulli(0.8)\n",
    "        g.gc_root = data['graph']['root']\n",
    "        dataset.append(g)\n",
    "\n",
    "    # фильтруем слишком маленькие или слишком большие графы\n",
    "    dataset = [g for g in dataset if 5 <= g.num_nodes() <= 50]\n",
    "    random.shuffle(dataset)\n",
    "\n",
    "    with open(result_dir, 'wb') as fp:\n",
    "        pickle.dump(dataset, fp)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd77be51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset: list,\n",
    "          company_embeddings_model_path: str,\n",
    "          embedding_tensor: torch.Tensor,\n",
    "          n_hidden: int = 32, n_out: int = 8,\n",
    "          max_no_improvements: int = 5,\n",
    "          print_each: int = 5,\n",
    "          n_epochs: int = 10):\n",
    "    \"\"\"\n",
    "    Обучает модель для решения задачи классификации ребер как находящихся внутри ГСК или ведущих вовне ГСК\n",
    "    Args:\n",
    "        dataset (list[dgl.DGLGraph]): датасет для обучения модели\n",
    "        company_embeddings_model_path (str): путь для сохранения\n",
    "        embedding_tensor: torch.Tensor,\n",
    "        n_hidden (int): размерность скрытых слоев модели\n",
    "        n_out (int): размерность выходного слоя модели\n",
    "        print_each (int): шаг для отображения текущих результатов внутри эпохи\n",
    "        max_no_improvements (int): максимальное кол-во эпох без улучшения качества\n",
    "        n_epochs\n",
    "    Returns:\n",
    "        SAGE: обученная модель для классификации ребер как находящихся внутри ГСК или ведущих вовне ГСК\n",
    "    \"\"\"\n",
    "    n_features = dataset[0].ndata['feats'].shape[1] + embedding_tensor.shape[1]\n",
    "    model = SAGE(n_features, n_hidden,\n",
    "                 n_out, n_layers=2,\n",
    "                 activation=F.relu, dropout=0.15,\n",
    "                 freeze=True,\n",
    "                 embedding_tensor=embedding_tensor)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "    all_labels = torch.cat([g.edata['label'] for g in dataset])\n",
    "    neg_counts, pos_counts = all_labels.bincount()\n",
    "    criterion = DotCeLossWith0kvedDistances(model.embeddings, pos_weight=pos_counts / neg_counts, okved_impact=0.5)\n",
    "    best_acc = 0\n",
    "    no_improvements = 0\n",
    "\n",
    "    dataloader = dgl.dataloading.GraphDataLoader(dataset, batch_size=256, shuffle=True, drop_last=False)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        train_correct, test_correct, train_total, test_total = 0, 0, 0, 0\n",
    "        epoch_test_preds = []\n",
    "        epoch_test_labels = []\n",
    "        for g in tqdm(dataloader):\n",
    "            node_features = g.ndata['feats'].float()\n",
    "            okveds = g.ndata['okved_code'].long()\n",
    "            edge_label = g.edata['label']\n",
    "            train_mask = g.edata['train_mask']\n",
    "            preds = model(g, node_features, okveds)\n",
    "            loss, score, labels = criterion(g, preds, okveds, edge_label, train_mask)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            train_predictions = (score.sigmoid() > 0.5)\n",
    "            train_correct += (train_predictions == labels).sum()\n",
    "            train_total += len(labels)\n",
    "            _, test_score, test_labels = criterion(g, preds, okveds, edge_label, ~train_mask)\n",
    "            test_predictions = (test_score.sigmoid() > 0.5)\n",
    "            test_correct += (test_predictions == test_labels).sum()\n",
    "            test_total += len(test_labels)\n",
    "            epoch_test_preds.extend(test_predictions.tolist())\n",
    "            epoch_test_labels.extend(test_labels.tolist())\n",
    "\n",
    "        test_acc = test_correct / test_total\n",
    "        train_acc = train_correct / train_total\n",
    "\n",
    "        if epoch % print_each == 0 or epoch == n_epochs - 1:\n",
    "            print(\n",
    "                f'{epoch=:05d} | loss={loss.item():.4f} | train_acc={train_acc.item():.4f} | test_acc={test_acc.item():.4f}')\n",
    "        if test_acc - best_acc >= 1e-3:\n",
    "            print(f'New best acc: {test_acc}!')\n",
    "            best_acc = test_acc\n",
    "            no_improvements = 0\n",
    "            torch.save(model, company_embeddings_model_path)\n",
    "        else:\n",
    "            no_improvements += 1\n",
    "        if no_improvements >= max_no_improvements:\n",
    "            print(f'No improvements in {max_no_improvements} epochs')\n",
    "            print(f'Best acc = {best_acc}')\n",
    "            break\n",
    "    model = torch.load(company_embeddings_model_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f59be33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_company_graph_with_embeddings(dataset: list, model: SAGE) -> dgl.DGLGraph:\n",
    "    \"\"\"\n",
    "    Строит граф, содержащий данные о всех компаниях датасета\n",
    "\n",
    "    Args:\n",
    "        dataset (list[dgl.DGLGraph]): датасет для обучения модели\n",
    "        model: обученная модель для классификации ребер как находящихся внутри ГСК или ведущих вовне ГСК\n",
    "    Returns:\n",
    "        граф, содержащий данные о всех компаниях датасета с эмбеддингами узлов на атрибутах\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    batch = dgl.batch(dataset)\n",
    "    batch_features = batch.ndata['feats'].float()\n",
    "    batch_okveds = batch.ndata['okved_code'].long()\n",
    "    all_embeddings = model(batch, batch__features, batch_okveds).detach()\n",
    "    batch.ndata['embeddings'] = all_embeddings\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83786c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем конфигурационный файл\n",
    "CONFIG = yaml.safe_load(open(\"CONFIG.yaml', encoding='utf8'))\n",
    "# получаем код ОКВЭД для каждой компании из датасета\n",
    "okved_parts = ['okved_class_', 'okved_subclass', 'okved_group', 'okved_subgroup', 'okved_type_']\n",
    "okved_data = pd.read_csv(CONFIG['paths']['okved_data_save'],\n",
    "                         index_col=0,\n",
    "                         dtype={c: str for c in okved_parts})\n",
    "\n",
    "# вспомогательные словари для маппинга ОКВЭДов в целые числа\n",
    "idx_to_okved = okved_data['okved'].to_dict()\n",
    "okved_to_idx = {v: k for k, v in idx_to_okved.items()}\n",
    "section_to_idx = {s: idx for idx, s in enumerate(okved_data['раздел'].unique())}\n",
    "okved_to_section = okved_data[['okved', 'раздел']].set_index('okved')['раздел'].map(section_to_idx).to_dict()\n",
    "\n",
    "# создаем тензор с эмбеддингами\n",
    "embedding_tensor = get_pretrained_embedding_tensor(idx_to_okved, CONFIG['paths']['okved_embeddings'])\n",
    "# загружаем датасет\n",
    "inout_path = CONFIG['paths']['inout_dataset']\n",
    "gc_path = CONFIG['paths']['gc_augmented_save']\n",
    "if isfile(inout_path):\n",
    "    with\n",
    "open(inout_path, 'rb') as fp:\n",
    "dataset = pickle.load(fp)\n",
    "else:\n",
    "dataset = create_dataset(gc_path, inout_path)\n",
    "# обучаем модель\n",
    "model = train(dataset,\n",
    "              company_embeddings_model_path=CONFIG['paths']['company_embeddings_model'],\n",
    "              embedding_tensor=embedding_tensor,\n",
    "              n_hidden=32,\n",
    "              n_out=8,\n",
    "              max_no_improvements=5,\n",
    "              print_each=5,\n",
    "              n_epochs=15)\n",
    "# собираем один большой граф, где есть все компании и их эмбеддинги\n",
    "batch = get_company_graph_with_embeddings(dataset, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0115a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gc_and_companies(dataset: list, lower: int, upper: int):\n",
    "    \"\"\"\n",
    "    Выводит на экран крупные ГСК и компании, которые в них входят\n",
    "    \"\"\"\n",
    "    gc_graph = {g.gc_root: g for g in dataset}\n",
    "    large_gcs = [g.gc_root for g in dataset if g.ndata['входит_в_ГСК'].bool().sum() >= 15][lower:upper]\n",
    "    for gc_id in large_gcs:\n",
    "        g = gc_graph[gc_id]\n",
    "        companies = g.ndata['company_id'][g.ndata['входит_в_ГСК'].bool()].tolist()\n",
    "        print(f'ID ГСК: {gc_id} Компании: {companies[:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08d2840c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gc_ranked_table(okved_data: pd.DataFrame,\n",
    "                          gc_id: int,\n",
    "                          node_id: int,\n",
    "                          model: SAGE,\n",
    "                          max_k: int = 20) -> None:\n",
    "    \"\"\"\n",
    "    Строит и выводит на экран таблицу близости компаний внутри ГСК gcid относительно целевой компании node_id\n",
    "    Args:\n",
    "        okved_data (pd.DataFrame): таблица с информацией об ОКВЭД\n",
    "        gc_id (int): ID целевой ГСК\n",
    "        node_id (int): ID целевого узла\n",
    "        model (SAGE): обученная модель для классификации ребер как находящихся внутри ГСК или ведущих вовне ГСК\n",
    "        max_k (int, optional): максимальное кол-во строк для вывода\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "def print_same_okved_ranked_table(batch: dgl.DGLGraph,\n",
    "                                  okved_data: pd.DataFrame,\n",
    "                                  idx_to_okved: dict,\n",
    "                                  gc_id: int,\n",
    "                                  node_id: int,\n",
    "                                  model: SAGE,\n",
    "                                  max_k: int = 20):\n",
    "    \"\"\"\n",
    "    Строит и выводит на экран таблицу близости компаний, имеющих одинаковый код ОКВЭД,\n",
    "    относительно целевой компании node id\n",
    "    Args:\n",
    "        batch (dgl.DGLGraph): граф, содержащий данные о всех компаниях датасета с эмбеддингами узлов на атрибутах\n",
    "        okved_data (pd.DataFrame): таблица с информацией об ОКВЭД\n",
    "        idx_to_okved (dict): маппинг номер кода ОКВЭД - код\n",
    "        gc_id (int): ID целевой ГСК\n",
    "        node_id (int): ID целевого узла\n",
    "        model (SAGE): обученная модель для классификации ребер как находящихся внутри ГСК или ведущих вовне ГСК\n",
    "        max_k (int, optional): максимальное кол-во строк для вывода\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a072da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gc_ranked_table(okved_data: pd.DataFrame,\n",
    "                          gc_id: int,\n",
    "                          node_id: int,\n",
    "                          model: SAGE,\n",
    "                          max_k: int = 20) -> None:\n",
    "    \"\"\"\n",
    "    Строит и выводит на экран таблицу близости компаний внутри ГСК gc_id относительно целевой компании node_id\n",
    "\n",
    "    Args:\n",
    "        okved_data (pd.DataFrame): таблица с информацией об ОКВЭД\n",
    "        gc_id (int): ID целевой ГСК\n",
    "        node_id (int): ID целевого узла\n",
    "        model (SAGE): обученная модель для классификации ребер как находящихся внутри ГСК или ведущих вовне ГСК\n",
    "        max_k (int, optional): максимальное кол-во строк для вывода\n",
    "    \"\"\"\n",
    "    gc_graph = {g.gc_root: g for g in dataset}\n",
    "    assert gc_id in gc_graph\n",
    "    g = gc_graph[gc_id]\n",
    "    with g.local_scope():\n",
    "        # получаем эмбеддинги для всех узлов\n",
    "        gc_embeddings = model(g, g.ndata['feats'].float(), g.ndata['okved_code'].long())\n",
    "        g.ndata['embeddings'] = gc_embeddings\n",
    "        # берем подграф на компаниях, входящих в ГСК\n",
    "        in_gc_mask = g.ndata['входит_в_ГСК'].bool()\n",
    "        h = g.subgraph(in_gc_mask)\n",
    "        # считаем расстояния между каждой парой узлов (на основе эмбеддингов)\n",
    "        gc_embeddings = h.ndata['embeddings'].detach()\n",
    "        pw_dists = torch.Tensor(pairwise_distances(gc_embeddings, metric='euclidean'))\n",
    "        # node_graph_idx - номер целевой компании в подграфе\n",
    "        node_graph_idx = (h.ndata['company_id'] == node_id).nonzero().item()\n",
    "        g.ndata.pop('embeddings')\n",
    "        # берем ближайшие компании\n",
    "        dist_from_source = pw_dists[node_graph_idx]\n",
    "        k = min(max_k, len(pw_dists))\n",
    "        values, indices = dist_from_source.topk(k, largest=False)\n",
    "        comp_id = h.ndata['company_id'][indices]\n",
    "        # … их коды ОКВЭД\n",
    "        okved_id = [idx_to_okved[i] for i in h.ndata['okved_code'][indices].tolist()]\n",
    "        okved_name = okved_data.set_index('okved')['name'][okved_id]\n",
    "        print(\"Целевой узел: \", node_id, \"ГСК: \", gc_id)\n",
    "        df = pd.DataFrame({'Ранг от целевого узла': np.arange(k),\n",
    "                           'Расстояние по эмбеддингам': values.tolist(),\n",
    "                           'ID компании': comp_id,\n",
    "                           'Код ОКВЭД': okved_id,\n",
    "                           'Код ОКВЭД с расшифровкой': okved_name,\n",
    "                           'Входит в ГСК': h.ndata['входит_в_ГСК'][indices].tolist()})\n",
    "        df['Ранг от целевого узла'] = np.arange(len(df))\n",
    "        display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359087ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_same_okved_ranked_table(batch: dgl.DGLGraph,\n",
    "                                  okved_data: pd.DataFrame,\n",
    "                                  idx_to_okved: dict,\n",
    "                                  gc_id: int,\n",
    "                                  node_id: int,\n",
    "                                  model: SAGE,\n",
    "                                  max_k: int = 20):\n",
    "    \"\"\"\n",
    "    Строит и выводит на экран таблицу близости компаний, имеющих одинаковый код ОКВЭД, \n",
    "    относительно целевой компании node id\n",
    "\n",
    "    Args:\n",
    "        batch (dgl.DGLGraph): граф, содержащий данные о всех компаниях датасета с эмбеддингами узлов на атрибутах\n",
    "        okved_data (pd.DataFrame): таблица с информацией об ОКВЭД\n",
    "        idx_to_okved (dict): маппинг номер кода ОКВЭД - код\n",
    "        gc_id (int): ID целевой ГСК\n",
    "        node_id (int): ID целевого узла\n",
    "        model (SAGE): обученная модель для классификации ребер как находящихся внутри ГСК или ведущих вовне ГСК\n",
    "        max_k (int, optional): максимальное кол-во строк для вывода\n",
    "    \"\"\"\n",
    "    gc_graph = {g.gc_root: g for g in dataset}\n",
    "    assert gc_id in gc_graph\n",
    "    target_g = gc_graph[gc_id]\n",
    "    okveds = target_g.ndata['okved_code'].long()\n",
    "    # находим номер ОКВЭД целевой компании\n",
    "    source_okved_id = okveds[(target_g.ndata['company_id'] == node_id).nonzero().item()]\n",
    "    # отбираем все компании с тем же кодом\n",
    "    same_okved_mask = batch.ndata['okved_code'] == source_okved_id\n",
    "    companies = batch.ndata['company_id'][same_okved_mask].tolist()\n",
    "    gc_ids = batch.ndata['gc_root'][same_okved_mask].tolist()\n",
    "    embs = {}\n",
    "    # итерируемся по компаниям с тем же ОКВЭД\n",
    "    for i, c in zip(gc_ids, companies):\n",
    "        # берем ГСК очередной компании и получаем эмбеддинги для всех узлов\n",
    "        g = gc_graph[i]\n",
    "        gc_embeddings = model(g, g.ndata['feats'].float(), g.ndata['okved_code'].long())\n",
    "        # забираем эмбеддинг интересующего нас узла и кладем в словарь\n",
    "        node_graph_idx = (g.ndata['company_id'] == c).nonzero().item()\n",
    "        embs[(i, c)] = gc_embeddings[node_graph_idx]\n",
    "\n",
    "    res = []\n",
    "    for (gid, cid), emb in embs.items():\n",
    "        res.append({'ID ГСК': gid,\n",
    "                    'ID Компании': cid,\n",
    "                    'Расстояние от целевой вершины': torch.dist(embs[(gc_id, node_id)], embs[(gid, cid)]).item()\n",
    "                    })\n",
    "\n",
    "    # ID ГСК читать как: узел из ГСК или около ГСК\n",
    "    print(\"Целевой узел: \", node_id, ' ГСК: ', gc_id, 'код ОКВЭД: ', idx_to_okved[source_okved_id.item()])\n",
    "    res = pd.DataFrame(res).sort_values(\"Расстояние от целевой вершины\").reset_index(drop=True).head(max_k)\n",
    "    display(res)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c771378",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_gc_and_companies(dataset, 0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2c8dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_gc_ranked_table(okved_data, gc_id=4755870, node_id=7887927, model=model, max_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103d39e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_same_okved_ranked_table(batch, okved_data, idx_to_okved, gc_id=4755870, node_id=7887927, model=model, max_k=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
