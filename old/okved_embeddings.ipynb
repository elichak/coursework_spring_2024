{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "get_ipython().run_line_magic('autoreload', '2')\n",
    "from imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def binarize_int(idx: int, n_bits: int) -> list:\n",
    "    \"\"\"\n",
    "    Переводит целое число в двоичную систему < заданным кол-вом бит и представляет\n",
    "    результат в виде списка\n",
    "\n",
    "    Args:\n",
    "        idx (int): целое число для преобразования\n",
    "        n_bits (int): кол-во бит для хранения двоичного числа\n",
    "\n",
    "    Return:\n",
    "        list[int]: представление числа в виде списка из n_bits нулей и единиц\n",
    "    \"\"\"\n",
    "    return [int(c) for c in format(idx, f'#@{n_bits+2}b')[2:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_node_features_with_gc(dir_: str, cols: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Получает таблицу со всеми значениями атрибутов всех узлов\n",
    "\n",
    "    Arg:\n",
    "        dir_ (str): путь к каталогу с pickle файлами с информацией о ГСК\n",
    "        cols (list[str]): список атрибутов для выбора\n",
    "\n",
    "    Return:\n",
    "        pd.DataFrame: таблица с информацией обо всех компаний в датасете\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    for fname in list(Path(dir_).iterdir()):\n",
    "        with open(fname, 'rb') as fp:\n",
    "            data = pickle.load(fp)\n",
    "            for item in data['nodes']:\n",
    "                item = {k: v for k, v in item.items() if k in cols}\n",
    "                item['ГСК'] = fname.stem\n",
    "                features.append(item)\n",
    "    df = pd.DataFrame(features)\n",
    "    df.drop_duplicates('id', inplace=True)\n",
    "    df.set_index('id', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_edge_features(dir_: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Получает фрейм co всеми значениями атрибутов связей (для дальнейшего кодирования)\n",
    "\n",
    "    Args:\n",
    "        dir_ (str): путь к каталогу с pickle файлами с информацией о ГСК\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: таблица с информацией обо всех связях в датасете\n",
    "    \"\"\"\n",
    "\n",
    "    features = []\n",
    "    for fname in list(Path(dir_).iterdir()):\n",
    "        with open(fname, 'rb') as fp:\n",
    "            data = pickle.load(fp)\n",
    "    features .extend(data['links'])\n",
    "    df = pd.DataFrame(features)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def push_reverse_eid_to_end(edge_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Сортирует ребра так, чтобы взаимообратные ребра находились на расстоянии len(edge df) // 2\n",
    "\n",
    "    Args:\n",
    "        edge_df (pd.DateFrame): таблица с ребрами\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: таблица < ребрами отсортированными так, чтобы взаимообратные ребра\n",
    "        находились на расстоянии len(edge df) // 2\n",
    "    \"\"\"\n",
    "    edge_df = edge_df.copy()\n",
    "    edges_sort = {}\n",
    "    curr_idx = 0\n",
    "    edge_to_eid = {(u, v): eid for eid, (u, v) in enumerate(edge_df[['u', 'v']].values)}\n",
    "    for (u, v) in edge_df[['u', 'v']].values:\n",
    "        if edge_to_eid[(u, v)] not in edges_sort:\n",
    "            edges_sort[edge_to_eid[(u, v)]] = curr_idx\n",
    "            edges_sort[edge_to_eid[(v, u)]] = curr_idx + len(edge_df) // 2\n",
    "            curr_idx += 1\n",
    "\n",
    "    edge_df['order'] = edge_df.index.map(edges_sort)\n",
    "    edge_df = edge_df.sort_values('order').reset_index(drop=True).drop(columns='order')\n",
    "    return edge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_gc_edges(company_df: pd.DataFrame,\n",
    "                    company_edges_df: pd.DataFrame,\n",
    "                    okved_to_idx: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Создает таблицу с ребрами на основе данных из ГСК\n",
    "\n",
    "    Args:\n",
    "        company_df (pd.DataFrame): таблица с данными о компаниях\n",
    "        company_edges_df (pd.DataFrame): таблица с данными о связях между компаниями\n",
    "        okved_to_idx (dict): маппинг код ответ - номер кода\n",
    "    Returns:\n",
    "        pd.DataFrame: таблица с ребрами между кодами ОКВЭД на основе данных о ГСК\n",
    "    \"\"\"\n",
    "    # ребра на основе ГСК\n",
    "    # обратные связи тут не добавляем, они были добавлены на этапе препроцессинга\n",
    "    company_to_okved = company_df['okved_code']\n",
    "\n",
    "    # добавляем к company edges_df информацию о ОКВЭД компаний, образующих ребро\n",
    "    gc_edges_data = (company_edges_df\n",
    "                     .merge(company_to_okved, left_on='source', right_index=True)\n",
    "                     .merge(company_to_okved, left_on='target', right_index=True)\n",
    "                     .loc[:, ['source', 'okved_code_x', 'target', 'okved_code_y', 'key']]\n",
    "                    )\n",
    "\n",
    "    # пока считаем все типы одинаковыми и считаем кол-во ребер между парами ОКВЭДов\n",
    "    gc_edges = gc_edges_data.groupby(['okved_code_x', 'okved_code_y']).size()\n",
    "\n",
    "    # убираем петли\n",
    "    gc_edges = gc_edges[gc_edges.index.get_level_values(1) != gc_edges.index.get_level_values(0)]\n",
    "    gc_edges = gc_edges.to_frame(name='weight').reset_index()\n",
    "\n",
    "    # характеристики для фильтрации ребер\n",
    "    # 0.25 квантили весов ребер от обеих вершин на ребре\n",
    "\n",
    "    gc_edges['g_wi'] = gc_edges.groupby('okved_code_x').transform(lambda x: x.quantile(0.25))['weight']\n",
    "    gc_edges['g_wj'] = gc_edges.groupby('okved_code_y').transform(lambda x: x.quantile(0.25))['weight']\n",
    "\n",
    "    # оставляем ребра с весами, большими 25% квантилей с обеих сторон\n",
    "    # минимальное значение квантиля 1, такие тоже обрасываем (знак >)\n",
    "\n",
    "    gc_edges = gc_edges.query('(weight > q_wi) & (weight > q_wj)').reset_index(drop=True)\n",
    "\n",
    "    # маппим названия ОКВЭД на целые числа и получаем веса ребер\n",
    "    edata_gc = (gc_edges[['okved_code_x', 'okved_code_y', 'weight']]\n",
    "                .rename(columns={'okved_code_x': 'u_code', 'okved_code_y': 'v_code'}))\n",
    "\n",
    "    edata_gc['u'] = edata_gc['u_code'].map(okved_to_idx)\n",
    "    edata_gc['v'] = edata_gc['v_code'].map(okved_to_idx)\n",
    "\n",
    "    # пересортируем ребра\n",
    "    edata_gc = push_reverse_eid_to_end(edata_gc)\n",
    "    half = len(edata_gc) // 2\n",
    "    assert np.all(edata_gc[:half][['u', 'v']].values == edata_gc[half: ][['v', 'u']].values)\n",
    "\n",
    "    return edata_gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_classifier_edges(okved_data: pd.DataFrame,\n",
    "                            okved_parts: list,\n",
    "                            gc_edges: pd.DataFrame,\n",
    "                            okved_to_idx: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cosgaer таблицу с ребрами Ha основе данных из Классификатора\n",
    "\n",
    "    Args:\n",
    "        okved_data (pd.DataFrame): таблица с данными о кодах ОКВЭД\n",
    "        okved_parts (list): список столбцов с 'частями' кодов\n",
    "        gc_edges (pd.DataFrame): таблица с ребрами между кодами ОКВЭД на основе данных о ГСК\n",
    "        okved_to_idx (dict): маппинг код ответ - номер кода\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: таблица c ребрами между кодами ОКВЭД на основе данных из Классификатора\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_classifier_weight(row, okved_tree):\n",
    "        u, v = row['u_code'], row['v_code']\n",
    "        weight = okved_tree.edges[u, v]['weight']\n",
    "        return weight\n",
    "\n",
    "\n",
    "    # ребра на основе классификатора\n",
    "    classifier_edges = set()\n",
    "    # итерируемся по смежным частям ОКВЭДОВ и добавляем ребра\n",
    "    for from_, to_ in zip(okved_parts, okved_parts[1:]):\n",
    "        possible_edges = okved_data[[from_, to_]].values\n",
    "        checked_edges = possible_edges[(pd.notna(possible_edges[:, 0])) &\n",
    "                                       (pd.notna(possible_edges[:, 1]))]\n",
    "        classifier_edges.update(tuple(t) for t in checked_edges.tolist())\n",
    "        # добавляем обратные связи\n",
    "        classifier_edges.update(tuple(t) for t in checked_edges[:,::-1]. tolist())\n",
    "    \n",
    "    # ребра от и к корню\n",
    "    classifier_edges.update(('root', v) for v in okved_datal['okved_class_'].dropna().unique())\n",
    "    classifier_edges.update((v, 'root') for м in okved_data['okved_class_'].dropna().unique())\n",
    "    \n",
    "    # на основе ребер построим дерево классификатора\n",
    "    okved_tree = nx.Graph()\n",
    "    okved_tree.add_edges_from(classifier_edges)\n",
    "    nx. set_edge_attributes(okved_tree, 1, 'weight')\n",
    "    \n",
    "    # на основе пар ОКВЭДОв из ГСК обновляем веса на ребрах классификатора\n",
    "    # строим пути между парами и добавляем +1 на каждое ребро\n",
    "    # тк работаем с деревом, кратчайший путь один\n",
    "    for pair in gc_edges[['u_code', 'v_code']].values:\n",
    "    \n",
    "        path = nx.shortest_path(okved_tree, *pair)\n",
    "        if len(path) > 2:\n",
    "            for u, v in zip(path, path[1:]):\n",
    "                okved_tree.edges[u, v]['weight'] += 1\n",
    "    \n",
    "    edata_classifier = pd.DataFrame(classifier_edges, columns=['u_code', 'v_code'])\n",
    "    # маппим названия ОКВЭД на целые числа и получаем веса ребер из классификатора\n",
    "    edata_classifier['wieght'] = edata_classifier.apply(get_classifier_weight, axis=1, okved_tree=okved_tree)\n",
    "    edata_classifier['u'] = edata_classifier['u_code'].map(okved_to_idx)\n",
    "    \n",
    "    edata_classifier['v'] = edata_classifier['v_code'].map(okved_to_idx)\n",
    "    \n",
    "    # пересортируем ребра\n",
    "    edata_classifier = push_reverse_eid_to_end(edata_classifier)\n",
    "    half = len(edata_classifier) // 2\n",
    "    assert np.all(edata_classifier[:half][['u', 'v']].values == edata_classifier[half:][['u', 'v']].values)\n",
    "    \n",
    "    return edata_classifier\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ndata(company_df: pd.DataFrame,\n",
    "                 okved_to_idx: dict,\n",
    "                 okved_data: pd.DataFrame,\n",
    "                 gc_edges: pd.DataFrame,\n",
    "                 okved_to_section: dict,\n",
    "                 bits_for_section: int = 5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Создает таблицу с данными об узлах (кодах ОКВЭД)\n",
    "\n",
    "    Arg:\n",
    "        company_df (pd.DataFrame): таблица с данными о компаниях\n",
    "        okved_to_idx (dict): маппинг код ОКВЭД - номер кода\n",
    "        okved_data (pd.DataFrame): таблица с данными о кодах ОКВЭД\n",
    "        gc_edges (pd.DataFrame): таблица с ребрами между кодами ОКВЭД на основе данных о ГСК\n",
    "        okved_to_section (dict): маппинг код раздела ОКВЭД - номер кода\n",
    "        bits_for_section (int, optional): количество символов для кодирования секции\n",
    "\n",
    "    Return:\n",
    "        pd.DataFrame: таблица с данными об узлах\n",
    "    \"\"\"\n",
    "    \n",
    "    def normalize(s):\n",
    "        return (s - s.mean()) / s.std()\n",
    "\n",
    " \n",
    "    # фичи об ОКВЭДах: кол-во компаний + эмбеддинг описания\n",
    "    ndata = pd.DataFrame({'okved_idx': okved_to_idx}) # уже выровнены по ОКВЭД\n",
    "    # считаем количество компаний по ОКВЭДам\n",
    "    ndata[ 'populerity'] = (company_df.reset_index()\n",
    "                            .groupby('okved_code')['id']\n",
    "                            .apply(len)\n",
    "                            .map(np.logip))\n",
    "                  \n",
    "    embedding_cols = [col for col in okved_data.columns if col.startswith('x_')]\n",
    "    ndata = ndate.merge(okved_data[embedding_cols], left_on='okved_idx', right_index=True, how='left').fillna(0.0)\n",
    "    ndata['out_degree'] = normalize(gc_edges.groupby('u_code').size().rename('out_degree'))\n",
    "    ndata['in_degree'] = normalize(gc_edges.groupby('v_code').size().rename('in_degree'))\n",
    "    ndata['wi'] = normalize(gc_edges.groupby('v_code')[ 'weight' ].sum().rename('wi'))\n",
    "    section_cols = [f'section_{i}' for i in range(bits_for_section)]\n",
    "    ndata[section_cols] = ndata['okved_idx'].map(okved_to_section).apply(binarize_int, n_bits=bits_for_section).tolist()\n",
    "    ndata.fillna(0, inplace-True)\n",
    "     \n",
    "    return ndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dgl_graph(edata_classifier: pd.DataFrame, edata_gc: pd.DataFrame, ndata: pd.DataFrame) -> dgl.DGLHeteroGraph:\n",
    "    \"\"\"\n",
    "    Создает граф на основе информации о ГСК и ОКВЭД\n",
    "\n",
    "    Args:\n",
    "        edata_classifier (pd.DataFrame): таблица с ребрами между кодами ОКВЭД на основе данных из Классификатора\n",
    "        едата_вс (dict): таблица с ребрами между кодами ОКВЭД на основе данных о ГСК\n",
    "        ndata (pd.DataFrame): таблица с данными об узлах\n",
    "\n",
    "    Returns:\n",
    "        dgl.DGLHeteroGraph: граф, в котором узлы - коды ОКВЭД, и имеются связи \n",
    "                            двух типов - на основе данных о ГСК и на основе Классификатора ОКВЭД\n",
    "    \"\"\"\n",
    "\n",
    "    # ребра от классификатора\n",
    "    classifier_src = edata_clessifier['u'].values\n",
    "    classifier_dst = edata_classifier['v'].values\n",
    "    # ребра от ГСК\n",
    "    gc_src = edata_ge['u'].values\n",
    "    gc_dst = edata_ge['v'].values\n",
    "\n",
    " \n",
    "\n",
    "    g_raw = dgl.heterograph({('okved', 'classifier', 'okved'): (classifier_src, classifier_dst), \n",
    "                             ('okved', 'вс', 'okved'): (gc_src, gc_dst)},\n",
    "                             num_nodes_dict={'okved': len(ndata)})\n",
    "\n",
    " \n",
    "  \n",
    "\n",
    "    # добавляем фичи на ребра и узлы\n",
    "\n",
    "    g_raw.ndata['features'] = torch.from_numpy(ndata.iloc[:, 1:].values)\n",
    "\n",
    "    g_raw.edges['classifier'].data['weight'] = torch.FloatTensor(edata_classifier['weight'])\n",
    "    g_raw.edges['вс'].data['weight'] = torch.FloatTensor(edate_gc['weight']. values)\n",
    "    g_raw.ndatal['okved_idx'] = torch.from_numpy(ndata.iloc[:, 0].values)\n",
    "\n",
    "    g_connected = dgl.node_subgraph(g_raw, (g_raw.in_degrees(etype='gc') > 0 ).nonzero().flatten())\n",
    "\n",
    "    half_n_edges = g_connected.num_edges('gc') // 2\n",
    "    half_train_size = (half_n_edges) * 8 // 10\n",
    "\n",
    "    half_perm = torch.randperm(half_n_edges)\n",
    "\n",
    "    train_forward = half_perm[:half_train_size]\n",
    "    train_reverse = train_forward + half_n_edges\n",
    "    test_forward = half_perm[half_train_size:]\n",
    "    test_reverse = test_forward + half_n_edges\n",
    "\n",
    "    train_edges = torch.cat([train_forward, train_reverse])\n",
    "    test_edges = torch.cat([test_forward, test_reverse])\n",
    "\n",
    "    g_connected.edges['gc'].data['train_mask'] = torch.zeros(g_connected.num_edges('gc')).to(torch.bool)\n",
    "    g_connected.edges['gc'].data['train_mask'][train_edges] = True\n",
    "\n",
    "    g_connected.edges['gc'].data['test_mask'] = torch.zeros(g_connected.num_edges('gc')).to(torch.bool)\n",
    "    g_connected.edges['gc'].data['test_mask'][test_edges] = True\n",
    "\n",
    "    return g_connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем конфигурационный файл\n",
    "\n",
    "CONFIG = yaml.safe_load(open('CONFIG. yaml', encoding='utf8'))\n",
    "node_features_path = CONFIG['paths']['gc_augmented_node_features']\n",
    "edge_features_path = CONFIG['paths']['gc_augmented_edge_features']\n",
    "gc_augmented_path = CONFIG['paths']['gc_augmented_save']\n",
    "\n",
    "                                     \n",
    "# создаем таблицу с информацией об атрибутах компаний\n",
    "if isfile(node_features_path):\n",
    "    company_df = pd.read_csv(node_features_path, index_col=0)\n",
    "else:\n",
    "    company_df = read_node_features_with_gc(gc_augmented_path,\n",
    "                                            cols=['id', 'okved_code', 'ГCK'])\n",
    "                                     \n",
    "company_df = company_df[company_df['okved_code'] != 'unknown']\n",
    "company_df.to_csv(node_features_path)\n",
    "\n",
    "\n",
    "# создаем таблицу с информацией об атрибутах связей между компаниями\n",
    "if isfile(edge_features_path):\n",
    "    company_edges_df = pd.read_csv(edge_features_path)\n",
    "else:\n",
    "    company_edges_df = read_edge_features(gc_augmented_path)\n",
    "    company_edges_df.to_csv(edge_features_path, index=False)\n",
    "\n",
    "# Оставляем только 5 типов отношений (самые частые, они еще и неориентированные)\n",
    "\n",
    "etypes_of_interest = {'e_legal_same_owner', 'e_gsk holder_leader_test',\n",
    "                      'e_legal_inn_same_owner', 'e_legal_inn_same_leader',\n",
    "                      'e_legal_same_leader'}\n",
    "  \n",
    "company_edges_df = company_edges_df[company_edges_df.key.isin(etypes_of_interest)]\n",
    "\n",
    " \n",
    "\n",
    "# Загружаем данные об ОКВЭД\n",
    "okved_parts = ['okved_class_', 'okved_subclass', 'okved_group', 'okved_subgroup', 'okved_type_']\n",
    "okved_data = pd.read_csv(CONFIG[ 'paths' ]['okved_data_save'],\n",
    "                         index_col=0,\n",
    "                         dtype={c: str for с in okved_parts})\n",
    "\n",
    " \n",
    "\n",
    "# вспомогательные словари для маппинга ОКВЭДов в целые числа\n",
    "\n",
    "idx_to_okved = dict(zip(okved_data.index, okved_data['okved']))\n",
    "\n",
    "okved_to_idx = dict(zip(okved_data['okved'], okved_data.index))\n",
    "\n",
    "section_to_idx = {section: idx for idx, section in enumerate(okved_datal['раздел'].unique())}\n",
    "okved_to_section = okved_datal['раздел'].map(section_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Start...')\n",
    "# создаем связи на основе информации о ГСК\n",
    "gc_edges = create_gc_edges(company_df, company_edges_df, okved_to_idx)\n",
    "print('gc edges created...')\n",
    "displey(gc_edges.head(2))\n",
    "# создаем связи Ha основе Классификатора\n",
    "classifier_edges = create_classifier_edges(okved_data, okved_parts, gc_edges, okved_to_idx)\n",
    "print('classifier edges created...')\n",
    "display(classifier_edges.head(2))\n",
    "# создаем таблицу © данными об узлах\n",
    "ndata = create_ndata(company_df, okved_to_idx, okved_data, gc_edges, okved_to_section)\n",
    "print('ndata created...')\n",
    "display(ndata.head(2))\n",
    "# создаем и сохраняем гетерограф\n",
    "g_connected = create_dgl_graph(classifier_edges, gc_edges, ndata)\n",
    "with open(CONFIG['paths']['okved_graph'], 'wb') as fp:\n",
    "    pickle.dump(g_connected, fp)\n",
    "print('graph created...')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
