{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07333a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "get_ipython().run_line_magic('autoreload', '2')\n",
    "\n",
    "from imports import *\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdda477a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.samplers import NegativeHeteroGraphSampler\n",
    "from models.rgcn import RGCN\n",
    "from models.loss import HeteroMLPCELoss, HeteroDotCELoss, HeteroDMCELoss, HeteroLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426f32ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(g: dgl.DGLHeteroGraph,\n",
    "                      n_layers: int = 2,\n",
    "                      neg_examples: int = 3,\n",
    "                      batch_size: int = 2500) -> dgl.dataloading.EdgeDataLoader:\n",
    "    \"\"\"\n",
    "    Создает даталоадер для обучения\n",
    "\n",
    "    Args:\n",
    "    Е (dgl.DGLHeteroGraph): граф с кодами ОКВЭД\n",
    "    n_layers (int, optional): количество слоев в RGCN\n",
    "    neg_examples (int, optional): количество отрицательных примеров на 1 положительный пример\n",
    "    batch_size (int, optional): количество ребер в одном батче для обучения\n",
    "\n",
    "    Returns:\n",
    "        dgl.DGLHeteroGraph: даталоадер для обучения\n",
    "    \"\"\"\n",
    "\n",
    "    # для обучения берем все ребра от классификатора и 80% от ГСК\n",
    "    train_eid_dict = {('okved', 'classifier', 'окуед'): g.edges(etype=('okved', 'classifier', 'okved'), form='eid'),\n",
    "                       ('okved', 'gc', 'okved'): g.edges['gc'].data['train_mask'].nonzero().flatten()}\n",
    "    \n",
    "    # для валидации берем 20% от ГСК\n",
    "    val_eid_dict = {('okved', 'classifier', 'okved'): g.edges(etype=('okved', 'classifier', 'okved'), form='eid'),\n",
    "                    ('okved', 'gc', 'okved'): g.edges['gc'].data['test_mask'].nonzero().flatten()}\n",
    "\n",
    "\n",
    "    reverse_eids_dict = {}\n",
    "    for etype in g.canonical_etypes:\n",
    "        Е = g.num_edges(etype) // 2\n",
    "        reverse_eids_dict[etype] = torch.cat([torch.arange(E, 2*Е), torch.arange(0, E)])\n",
    "\n",
    "    sampler = dgl.dataloading.MultiLayerFullNeighborSampler(n_layers)\n",
    "    dataloader = dgl.dataloading.EdgeDataloader(g, train_eid_dict, sampler,\n",
    "                                                negative_sampler=NegativeHeteroGraphSampler(g,\n",
    "                                                                                            neg_examples=neg_examples,\n",
    "                                                                                            gamma=0),\n",
    "                                                \n",
    "                                                reverse_eids = reverse_eids_dict,\n",
    "                                                batch_size=batch_size,\n",
    "                                                shuffle=True,\n",
    "                                                drop_last=False)\n",
    "\n",
    "    return dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5fd8dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(in_feats: int,\n",
    "                 n_hidden: int,\n",
    "                 n_out: int,\n",
    "                 n_layers: int,\n",
    "                 dropout_p: float,\n",
    "                 device: str) -> RGCN:\n",
    "    \"\"\"\n",
    "    Создает модель для обучения\n",
    "    Args:\n",
    "        in_feats (int): количество атрибутов на узлах графа\n",
    "        n_hidden (int): размерность скрытых слоев модели\n",
    "        n_out (int): размерность выходного слоя модели\n",
    "        n_layers (int): количество скрытых слоев модели\n",
    "        dropout_p (float): вероятность дропаута\n",
    "        device (str): устройство для обучения (на наших машинах - только cpu)\n",
    "    Returns:\n",
    "        dgl.DGLHeteroGraph: даталоадер для обучения\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    model = RGCN(in_feats, n_hidden, n_out, n_layers, F.reply, dropout_p, g.etypes)\n",
    "    model = model.to(device)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085b5a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: RGCN,\n",
    "          criterion: HeteroLoss,\n",
    "          dataloader: dgl.dataloading.EdgeDataLoader,\n",
    "          g: dgl.DGLHeteroGraph,\n",
    "          okved_embeddings_model_path: str,\n",
    "          n_epochs: int = 100,\n",
    "          log_every: int = 10,\n",
    "          max_no_improvements: int = 5) -> tuple:\n",
    "    \"\"\"\n",
    "        Обучает модель\n",
    "    Args:\n",
    "        model (RGCN): модель для обучения\n",
    "        criterion (HeteroLoss): функция потерь\n",
    "        dataloader (dgl.dataloading.EdgeDataLoader): даталоадер для обучения\n",
    "        g (dgl.DGLHeteroGraph): граф для обучения\n",
    "        okved_embeddings_model_path (str): путь для сохранения модели\n",
    "        n_epochs (int): количество эпох для обучения\n",
    "        log_every (int): шаг для отображения текущих результатов внутри эпохи\n",
    "        max_no_improvements (int): максимальное кол-во эпох без улучшения качества\n",
    "    Returns:\n",
    "    tuple: обученная модель и результаты работы с последней эпохи\n",
    "    \"\"\"\n",
    "\n",
    "    nfeat = g.ndata['features']\n",
    "    best_acc = 0\n",
    "    no_improvements = 0\n",
    "    optimizer = optim.AdamW([{\"params\": model.parameters()}, {\"params\": criterion.parameters()}], lr=.001)\n",
    "    epochs_accs = []\n",
    "    no_improvements = 0\n",
    "    for epoch in range(0, n_epochs):\n",
    "        curr_epoch_labels = []\n",
    "        curr_epoch_preds = []\n",
    "        curr_epoch_probas = []\n",
    "        for step, (input_nodes, pos_graph, neg_graph, blocks) in tqdm(enumerate(dataloader)):\n",
    "            batch_inputs = {'okved': nfeat[input_nodes].to(device).float()}\n",
    "            pos_graph = pos_graph.to(device)\n",
    "            neg_graph = neg_graph.to(device)\n",
    "\n",
    "            blocks = [block.to(device) for block in blocks]\n",
    "            batch_pred = model(blocks, batch_inputs)\n",
    "\n",
    "            loss, score, label = criterion(batch_pred, pos_graph, neg_graph)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            predictions = (score.sigmoid() > 0.5).long().flatten()\n",
    "\n",
    "            curr_epoch_labels.extend(label.detach().numpy())\n",
    "            curr_epoch_preds.extend(predictions.detach().numpy())\n",
    "            curr_epoch_probes.extend(score.flatten().sigmoid().detach().numpy())\n",
    "\n",
    "            if step % log_every == 0:\n",
    "                acc = (predictions == label).sum() / len(label)\n",
    "                print(f'{epoch=:05d} | {step=:05d} | loss={loss.item():.4f} | train_acc={acc.item():.4f}')\n",
    "        curr_epoch_result = {\"labels\": curr_epoch_labels, \"preds\": curr_epoch_preds, 'probas': curr_epoch_probas}\n",
    "\n",
    "        e_acc = (torch.LongTensor(curr_epoch_preds) == torch.LongTensor(curr_epoch_labels)).sum() / len(curr_epoch_labels)\n",
    "        epochs_accs.append(e_acc.item())\n",
    "        print(f'Epoch={epoch:05d} train_acc: {e_acc.item():.4f} ')\n",
    "        if e_acc - best_acc >= 1e-3:\n",
    "            print(f'New best acc: {e_acc}!')\n",
    "            best_acc = e_acc\n",
    "            no_improvements = 0\n",
    "            torch.save(model, okved_embeddings_model_path)\n",
    "        else:\n",
    "            no_improvements += 1\n",
    "        if no_improvements >= max_no_improvements:\n",
    "            print(f'No improvements in {max_no_improvements} epochs')\n",
    "            print(f'Best acc = {best_acc}')\n",
    "            break\n",
    "\n",
    "    model = torch.load(okved_embeddings_model_path)\n",
    "    return model, curr_epoch_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52808280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_train_results(metrics: dict) -> None:\n",
    "    \"\"\"\n",
    "    Выводит ROC-кривую и матрицу несоответствий\n",
    "    Args:\n",
    "        metrics (dict): результаты работы с последней эпохи\n",
    "    \"\"\"\n",
    "    \n",
    "def evaluate(g: dgl.DGLHeteroGraph, all_embeddings: torch.Tensor) -> None:\n",
    "    \"\"\"\n",
    "    Оценивает аccuracy на тестовом множестве\n",
    "    Args:\n",
    "        g (dgl.DGLHeteroGraph): граф для обучения\n",
    "        all_embeddings (torch.Tensor): тензор эмбеддингов узлов\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eb6dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_train_results(metrics: dict) -> None:\n",
    "    \"\"\"\n",
    "    Выводит ROC-кривую и матрицу несоответствий\n",
    "    Args:\n",
    "        metrics (dict): результаты работы с последней эпохи\n",
    "    \"\"\"\n",
    "    fpr, tpr, thresholds = roc_curve(metrics['labels'], metrics['probas'])\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', label='Random')\n",
    "    plt.plot(fpr, tpr, linestyle='solid', label='Model')\n",
    "    plt.xlabel(\"FPR\")\n",
    "    plt.ylabel(\"TPR\")\n",
    "    plt.legend()\n",
    "    cm = pd.DataFrame(confusion_matrix(metrics['labels'], metrics['preds']), \n",
    "                      index=['y=0', 'y=1'], columns=['y^=0', 'y^=1'])\n",
    "    display(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1751bff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(g: dgl.DGLHeteroGraph, all_embeddings: torch.Tensor) -> None:\n",
    "    \"\"\"\n",
    "    Оценивает аcсuracy на тестовом множестве\n",
    "    Args:\n",
    "        g (dgl.DGLHeteroGraph): граф для обучения\n",
    "        all_embeddings (torch.Tensor): тензор эмбеддингов узлов\n",
    "    \"\"\"\n",
    "    with g.local_scope():\n",
    "        g.ndata['h'] = all_embeddings\n",
    "        g.apply_edges(criterion.apply_edges, etype='gc')\n",
    "        logits = g.edges['gc'].data['score']\n",
    "        test_preds = (logits[g.edges['gc'].data['test_mask'], 0].sigmoid() > 0.5).long()\n",
    "        test_true = torch.ones_like(test_preds)\n",
    "        test_acc = (test_preds == test_true).sum() / len(test_true)\n",
    "        print(f'Test_acc: {test_acc.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1527d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем конфигурационный файл\n",
    "CONFIG = yaml.safe_load(open('CONFIG.yaml', encoding='utf8'))\n",
    "\n",
    "# Загружаем данные об ОКВЭД\n",
    "okved_parts = ['okved_class_', 'okved_subclass', 'okved_group', 'okved_subgroup', 'okved_type_']\n",
    "okved_data = pd.read_csv(CONFIG['paths']['okved_data_save'],\n",
    "                         index_col=0,\n",
    "                         dtype={c: str for c in okved_parts})\n",
    "\n",
    "# вспомогательные словари для маппинга ОКВЭДов в целые числа\n",
    "idx_to_okved = okved_data['okved'].to_dict()\n",
    "section_to_idx = {s: idx for idx, s in enumerate(okved_data['раздел'].unique())}\n",
    "okved_to_section = okved_data[['okved', 'раздел']].set_index('okved')['раздел'].map(section_to_idx).to_dict()\n",
    "\n",
    "# загружаем гетерограф\n",
    "with open(CONFIG['paths']['okved_graph'], 'rb') as fp:\n",
    "    g = pickle.load(fp)\n",
    "\n",
    "# создаем и обучаем модель\n",
    "device = 'cpu'\n",
    "assert device == 'cpu'\n",
    "dataloader = create_dataloader(g, n_layers=2)\n",
    "model = create_model(in_feats=g.ndata['features'].shape[1],\n",
    "                     n_hidden=128,\n",
    "                     n_out=32,\n",
    "                     n_layers=2,\n",
    "                     dropout_p=0.25,\n",
    "                     device=device)\n",
    "\n",
    "criterion = HeteroDMCELoss(emb_size=model.n_classes, train_on_gc=True)\n",
    "\n",
    "model, metrics = train(model, criterion, dataloader, g,\n",
    "                       CONFIG['paths']['okved_embeddings_model'],\n",
    "                       n_epochs=50, log_every=10, max_no_improvements=5)\n",
    "\n",
    "# визуализируем результат\n",
    "visualize_train_results(metrics)\n",
    "all_embeddings = model.get_embeddings(g)['okved']\n",
    "evaluate(g, all_embeddings)\n",
    "\n",
    "# сохраняем эмбеддинги кодов ОКВЭД\n",
    "names = np.array([idx_to_okved[idx] for idx in g.ndata['okved_idx'].numpy()])\n",
    "name_emb = dict(zip(names, all_embeddings.tolist()))\n",
    "with open(CONFIG['paths']['okved_embeddings'], 'wb') as fp:\n",
    "    pickle.dump(name_emb, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4782067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_2d(embeddings_2d: np.array,\n",
    "            g: dgl.DGLHeteroGraph,\n",
    "            okved_data: pd.DataFrame,\n",
    "            okved_to_section: dict,\n",
    "            idx_to_okved: dict,\n",
    "            xlim: tuple = None,\n",
    "            ylim: tuple = None,\n",
    "            figsize: tuple = (15, 5),\n",
    "            annotate: bool = False,\n",
    "            name_len: int = 20,\n",
    "            hide_spins: tuple = None,\n",
    "            node_size: int = 5) -> None:\n",
    "    \"\"\"\n",
    "    Рисует проекции эмбеддингов на плоскости\n",
    "    Args:\n",
    "        embeddings_2d (np.array): массив эмбеддингов узлов\n",
    "        g (dgl.DGLHeteroGraph): граф для обучения\n",
    "        okved_data (pd.DataFrame): таблица с информацией об ОКВЭД\n",
    "        okved_to_section (dict): маппинг код раздела ОКВЭД - номер кода\n",
    "        idx_to_okved (dict): маппинг номер кода ОКВЭД - код\n",
    "        xlim (tuple, optional): ограничения по оси х\n",
    "        ylim (tuple, optional): ограничения по оси у\n",
    "        figsize (tuple, optional): размер фигуры\n",
    "        annotate (bool, optional): True, если нужно добавить подписи к точкам (лучше не применять на полном датасете)\n",
    "        name_len (int, optional): максимальная длина названия кода\n",
    "        hide_spins (tuple, optional): какие рамки скрывать\n",
    "        node_size (int, optional): размер точки\n",
    "    \"\"\"\n",
    "\n",
    "    def cut(s: str, ln: int = 10) -> str:\n",
    "        if len(s) >= ln:\n",
    "            return s[:ln - 3] + '...'\n",
    "        return s\n",
    "\n",
    "    colors = np.array([okved_to_section[idx_to_okved[idx]] for idx in g.ndata['okved_idx'].numpy()])\n",
    "    names = np.array([idx_to_okved[idx] + ' ' + cut(okved_data.loc[idx, 'name'], name_len)\n",
    "                      for idx in g.ndata['okved_idx'].numpy()])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    if xlim:\n",
    "        x_mask = (embeddings_2d[:, 0] >= xlim[0]) & (embeddings_2d[:, 0] <= xlim[1])\n",
    "    else:\n",
    "        x_mask = np.ones(len(embeddings_2d)).astype(bool)\n",
    "    if ylim:\n",
    "        y_mask = (embeddings_2d[:, 1] >= ylim[0]) & (embeddings_2d[:, 1] <= ylim[1])\n",
    "\n",
    "    else:\n",
    "        y_mask = np.ones(len(embeddings_2d)).astype(bool)\n",
    "\n",
    "    mask = x_mask & y_mask\n",
    "    embs = embeddings_2d[mask]\n",
    "\n",
    "    colors = colors[mask]\n",
    "    names = names[mask]\n",
    "    ax.scatter(embs[:, 0], embs[:, 1], s=node_size, c=colors)\n",
    "    ax.set_xlabel('$h_0(v)$')\n",
    "    ax.set_ylabel('$h_1(v)$')\n",
    "    if annotate:\n",
    "        for (x, y), txt in zip(embs, names):\n",
    "            ax.text(x, y, txt, rotation=45)\n",
    "    if xlim:\n",
    "        ax.set_xlim(*xlim)\n",
    "    if ylim:\n",
    "        ax.set_ylim(*ylim)\n",
    "    if hide_spins is not None:\n",
    "        for spin in hide_spins:\n",
    "            ax.spines[spin].set_visible(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578aaa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_2d = TSNE(2, random_state=43).fit_transform(all_embeddings.detach())\n",
    "g.ndata['x'] = torch.from_numpy(embeddings_2d[:, 0])\n",
    "g.ndata['y'] = torch.from_numpy(embeddings_2d[:, 1])\n",
    "draw_2d(embeddings_2d, g, okved_data, okved_to_section, idx_to_okved, annotate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
