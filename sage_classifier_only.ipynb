{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
    "import dgl\n",
    "import dgl.data\n",
    "import dgl.function as fn\n",
    "import dgl.nn as gnn\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NegativeSampler(object):\n",
    "    def __init__(self, g, k, neg_share=False, device=None):\n",
    "        if device is None:\n",
    "            device = g.device\n",
    "        self.weights = g.in_degrees().float().to(device) ** 0.75\n",
    "        self.k = k\n",
    "        self.neg_share = neg_share\n",
    "\n",
    "    def __call__(self, g):\n",
    "        src, _ = g.edges()\n",
    "        n = len(src)\n",
    "        if self.neg_share and n % self.k == 0:\n",
    "            dst = self.weights.multinomial(n, replacement=True)\n",
    "            dst = dst.view(-1, 1, self.k).expand(-1, self.k, -1).flatten()\n",
    "        else:\n",
    "            dst = self.weights.multinomial(n*self.k, replacement=True)\n",
    "        src = src.repeat_interleave(self.k)\n",
    "        return dgl.graph((src, dst), num_nodes=g.num_nodes())\n",
    "\n",
    "class CrossEntropyLoss(nn.Module):\n",
    "    def forward(self, h, pos_graph, neg_graph):\n",
    "        with pos_graph.local_scope():\n",
    "            pos_graph.ndata['h'] = h\n",
    "            pos_graph.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
    "            pos_score = pos_graph.edata['score']\n",
    "        with neg_graph.local_scope():\n",
    "            neg_graph.ndata['h'] = h\n",
    "            neg_graph.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
    "            neg_score = neg_graph.edata['score']\n",
    "\n",
    "        score = th.cat([pos_score, neg_score])\n",
    "        label = th.cat([th.ones_like(pos_score), th.zeros_like(neg_score)]).long()\n",
    "        loss = F.binary_cross_entropy_with_logits(score, label.float())\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sage(nn.Module):\n",
    "    def __init__(self, in_feats, n_hidden, n_classes, n_layers, activation, dropout):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_classes = n_classes\n",
    "        self.layers = nn.ModuleList()\n",
    "        if n_layers > 1:\n",
    "            self.layers.append(gnn.SAGEConv(in_feats, n_hidden, aggregator_type='mean'))\n",
    "            for i in range(1, n_layers - 1):\n",
    "                self.layers.append(gnn.SAGEConv(n_hidden, n_hidden, aggregator_type='mean'))\n",
    "            self.layers.append(gnn.SAGEConv(n_hidden, n_classes, aggregator_type='mean'))\n",
    "        else:\n",
    "            self.layers.append(gnn.SAGEConv(in_feats, n_classes, aggregator_type='mean'))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        h = x\n",
    "        for l, layer in enumerate(self.layers):\n",
    "            h = layer(g, h)\n",
    "            if l != len(self.layers) - 1:\n",
    "                h = self.activation(h)\n",
    "                h = self.dropout(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/graph/okved_graph.pickle', 'rb') as fp:\n",
    "    g = pickle.load(fp)\n",
    "\n",
    "clf_graph = dgl.edge_subgraph(graph=g, \n",
    "                              edges=(g.edata['type'] == 1).nonzero().flatten())\n",
    "clf_graph = g\n",
    "okved_data = pd.read_csv('../data/okved2/okved_2014_w_sections.csv', index_col=0)\n",
    "sections = okved_data['section_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=2637, num_edges=438730,\n",
       "      ndata_schemes={'feat': Scheme(shape=(312,), dtype=torch.float64)}\n",
       "      edata_schemes={'weight': Scheme(shape=(), dtype=torch.int64), 'type': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'norm': Scheme(shape=(), dtype=torch.float32)})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=2637, num_edges=438730,\n",
       "      ndata_schemes={'feat': Scheme(shape=(312,), dtype=torch.float64)}\n",
       "      edata_schemes={'weight': Scheme(shape=(), dtype=torch.int64), 'type': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'norm': Scheme(shape=(), dtype=torch.float32)})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(g.edata['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=2637, num_edges=438730,\n",
       "      ndata_schemes={'feat': Scheme(shape=(312,), dtype=torch.float64)}\n",
       "      edata_schemes={'weight': Scheme(shape=(), dtype=torch.int64), 'type': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'norm': Scheme(shape=(), dtype=torch.float32)})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g # число ребер- 438730, число узлов-2637"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2637, 312])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.ndata['feat'].shape # 312 - размерность пространства признаков (осталось понять, что это за признаки)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['weight', 'type', 'train_mask', 'norm'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.edata.keys() # ключи в данных о ребрах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([438730])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.edata['weight'].shape # для каждого узла свой вес (берем его из ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([438730])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.edata['type'].shape # для каждого узла свой тип связи (берем его из ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2]), tensor([175868,   5272, 257590]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.unique(g.edata['type'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([438730])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.edata['train_mask'].shape # для каждого узла свой вес (берем его из ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([False,  True]), tensor([ 87746, 350984]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.unique(g.edata['train_mask'], return_counts=True) # train_test_split????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([438730])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.edata['norm'].shape # для каждого узла свой вес (берем его из ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3.2410e-04, 3.6836e-04, 3.9812e-04,  ..., 5.7735e-01, 6.7700e-01,\n",
       "         7.0711e-01]),\n",
       " tensor([  2,   2,   2,  ..., 798,   2,   4]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "th.unique(g.edata['norm'], return_counts=True) # ну это что-то с чем-то..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_okved(s: str) -> tuple:\n",
    "    class_, subclass, group, subgroup, type_ = ['None'] * 5\n",
    "    assert len(s) in {2, 4, 5, 7, 8}\n",
    "    class_ = s[:2]\n",
    "    if len(s) >= 4:\n",
    "        subclass = s[:4]\n",
    "    if len(s) >= 5:\n",
    "        group = s[:5]\n",
    "    if len(s) >= 7:\n",
    "        subgroup = s[:7]\n",
    "    if len(s) == 8:\n",
    "        type_ = s\n",
    "    return class_, subclass, group, subgroup, type_\n",
    "\n",
    "def build_nfeat_from_okved_data(okved_data) -> th.Tensor:\n",
    "    nfeat = np.full((len(okved_data)+1, 6), 'None', dtype=object)\n",
    "    nfeat[1:, :-1] = np.array(okved_data['native_code'].map(split_okved).tolist())\n",
    "    nfeat[1:, -1] = sections\n",
    "    nfeat = ce.OrdinalEncoder().fit_transform(nfeat).values\n",
    "    nfeat = StandardScaler().fit_transform(nfeat)\n",
    "    nfeat = th.from_numpy(nfeat).float()   \n",
    "    return nfeat  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000 |  Loss 1.9893\n",
      "Epoch 00001 |  Loss 1.8887\n",
      "Epoch 00002 |  Loss 1.7659\n",
      "Epoch 00003 |  Loss 1.6600\n",
      "Epoch 00004 |  Loss 1.5674\n",
      "Epoch 00005 |  Loss 1.4714\n",
      "Epoch 00006 |  Loss 1.3888\n",
      "Epoch 00007 |  Loss 1.3225\n",
      "Epoch 00008 |  Loss 1.2554\n",
      "Epoch 00009 |  Loss 1.1976\n",
      "Epoch 00010 |  Loss 1.1565\n",
      "Epoch 00011 |  Loss 1.0849\n",
      "Epoch 00012 |  Loss 1.0679\n",
      "Epoch 00013 |  Loss 1.0215\n",
      "Epoch 00014 |  Loss 0.9740\n",
      "Epoch 00015 |  Loss 0.9481\n",
      "Epoch 00016 |  Loss 0.9195\n",
      "Epoch 00017 |  Loss 0.8894\n",
      "Epoch 00018 |  Loss 0.8701\n",
      "Epoch 00019 |  Loss 0.8543\n",
      "Epoch 00020 |  Loss 0.8361\n",
      "Epoch 00021 |  Loss 0.8282\n",
      "Epoch 00022 |  Loss 0.8097\n",
      "Epoch 00023 |  Loss 0.7942\n",
      "Epoch 00024 |  Loss 0.7864\n",
      "Epoch 00025 |  Loss 0.7751\n",
      "Epoch 00026 |  Loss 0.7695\n",
      "Epoch 00027 |  Loss 0.7602\n",
      "Epoch 00028 |  Loss 0.7550\n",
      "Epoch 00029 |  Loss 0.7494\n",
      "Epoch 00030 |  Loss 0.7435\n",
      "Epoch 00031 |  Loss 0.7379\n",
      "Epoch 00032 |  Loss 0.7358\n",
      "Epoch 00033 |  Loss 0.7316\n",
      "Epoch 00034 |  Loss 0.7271\n",
      "Epoch 00035 |  Loss 0.7244\n",
      "Epoch 00036 |  Loss 0.7218\n",
      "Epoch 00037 |  Loss 0.7201\n",
      "Epoch 00038 |  Loss 0.7178\n",
      "Epoch 00039 |  Loss 0.7160\n",
      "Epoch 00040 |  Loss 0.7133\n",
      "Epoch 00041 |  Loss 0.7119\n",
      "Epoch 00042 |  Loss 0.7108\n",
      "Epoch 00043 |  Loss 0.7096\n",
      "Epoch 00044 |  Loss 0.7071\n",
      "Epoch 00045 |  Loss 0.7061\n",
      "Epoch 00046 |  Loss 0.7057\n",
      "Epoch 00047 |  Loss 0.7043\n",
      "Epoch 00048 |  Loss 0.7035\n",
      "Epoch 00049 |  Loss 0.7021\n",
      "Epoch 00050 |  Loss 0.7016\n",
      "Epoch 00051 |  Loss 0.7009\n",
      "Epoch 00052 |  Loss 0.7006\n",
      "Epoch 00053 |  Loss 0.6993\n",
      "Epoch 00054 |  Loss 0.6989\n",
      "Epoch 00055 |  Loss 0.6982\n",
      "Epoch 00056 |  Loss 0.6980\n",
      "Epoch 00057 |  Loss 0.6967\n",
      "Epoch 00058 |  Loss 0.6968\n",
      "Epoch 00059 |  Loss 0.6963\n",
      "Epoch 00060 |  Loss 0.6959\n",
      "Epoch 00061 |  Loss 0.6954\n",
      "Epoch 00062 |  Loss 0.6949\n",
      "Epoch 00063 |  Loss 0.6946\n",
      "Epoch 00064 |  Loss 0.6940\n",
      "Epoch 00065 |  Loss 0.6941\n",
      "Epoch 00066 |  Loss 0.6936\n",
      "Epoch 00067 |  Loss 0.6936\n",
      "Epoch 00068 |  Loss 0.6928\n",
      "Epoch 00069 |  Loss 0.6927\n",
      "Epoch 00070 |  Loss 0.6923\n",
      "Epoch 00071 |  Loss 0.6924\n",
      "Epoch 00072 |  Loss 0.6920\n",
      "Epoch 00073 |  Loss 0.6916\n",
      "Epoch 00074 |  Loss 0.6915\n",
      "Epoch 00075 |  Loss 0.6915\n",
      "Epoch 00076 |  Loss 0.6915\n",
      "Epoch 00077 |  Loss 0.6912\n",
      "Epoch 00078 |  Loss 0.6907\n",
      "Epoch 00079 |  Loss 0.6910\n",
      "Epoch 00080 |  Loss 0.6905\n",
      "Epoch 00081 |  Loss 0.6906\n",
      "Epoch 00082 |  Loss 0.6903\n",
      "Epoch 00083 |  Loss 0.6901\n",
      "Epoch 00084 |  Loss 0.6901\n",
      "Epoch 00085 |  Loss 0.6901\n",
      "Epoch 00086 |  Loss 0.6896\n",
      "Epoch 00087 |  Loss 0.6896\n",
      "Epoch 00088 |  Loss 0.6892\n",
      "Epoch 00089 |  Loss 0.6890\n",
      "Epoch 00090 |  Loss 0.6893\n",
      "Epoch 00091 |  Loss 0.6889\n",
      "Epoch 00092 |  Loss 0.6890\n",
      "Epoch 00093 |  Loss 0.6886\n",
      "Epoch 00094 |  Loss 0.6886\n",
      "Epoch 00095 |  Loss 0.6884\n",
      "Epoch 00096 |  Loss 0.6881\n",
      "Epoch 00097 |  Loss 0.6884\n",
      "Epoch 00098 |  Loss 0.6879\n",
      "Epoch 00099 |  Loss 0.6876\n",
      "Epoch 00100 |  Loss 0.6874\n",
      "Epoch 00101 |  Loss 0.6877\n",
      "Epoch 00102 |  Loss 0.6876\n",
      "Epoch 00103 |  Loss 0.6873\n",
      "Epoch 00104 |  Loss 0.6873\n",
      "Epoch 00105 |  Loss 0.6870\n",
      "Epoch 00106 |  Loss 0.6870\n",
      "Epoch 00107 |  Loss 0.6868\n",
      "Epoch 00108 |  Loss 0.6867\n",
      "Epoch 00109 |  Loss 0.6867\n",
      "Epoch 00110 |  Loss 0.6861\n",
      "Epoch 00111 |  Loss 0.6865\n",
      "Epoch 00112 |  Loss 0.6861\n",
      "Epoch 00113 |  Loss 0.6860\n",
      "Epoch 00114 |  Loss 0.6859\n",
      "Epoch 00115 |  Loss 0.6854\n",
      "Epoch 00116 |  Loss 0.6857\n",
      "Epoch 00117 |  Loss 0.6854\n",
      "Epoch 00118 |  Loss 0.6852\n",
      "Epoch 00119 |  Loss 0.6852\n",
      "Epoch 00120 |  Loss 0.6853\n",
      "Epoch 00121 |  Loss 0.6847\n",
      "Epoch 00122 |  Loss 0.6846\n",
      "Epoch 00123 |  Loss 0.6845\n",
      "Epoch 00124 |  Loss 0.6842\n",
      "Epoch 00125 |  Loss 0.6841\n",
      "Epoch 00126 |  Loss 0.6839\n",
      "Epoch 00127 |  Loss 0.6835\n",
      "Epoch 00128 |  Loss 0.6837\n",
      "Epoch 00129 |  Loss 0.6837\n",
      "Epoch 00130 |  Loss 0.6831\n",
      "Epoch 00131 |  Loss 0.6834\n",
      "Epoch 00132 |  Loss 0.6822\n",
      "Epoch 00133 |  Loss 0.6822\n",
      "Epoch 00134 |  Loss 0.6822\n",
      "Epoch 00135 |  Loss 0.6826\n",
      "Epoch 00136 |  Loss 0.6819\n",
      "Epoch 00137 |  Loss 0.6821\n",
      "Epoch 00138 |  Loss 0.6816\n",
      "Epoch 00139 |  Loss 0.6817\n",
      "Epoch 00140 |  Loss 0.6813\n",
      "Epoch 00141 |  Loss 0.6806\n",
      "Epoch 00142 |  Loss 0.6810\n",
      "Epoch 00143 |  Loss 0.6810\n",
      "Epoch 00144 |  Loss 0.6805\n",
      "Epoch 00145 |  Loss 0.6799\n",
      "Epoch 00146 |  Loss 0.6802\n",
      "Epoch 00147 |  Loss 0.6800\n",
      "Epoch 00148 |  Loss 0.6798\n",
      "Epoch 00149 |  Loss 0.6795\n",
      "Epoch 00150 |  Loss 0.6790\n",
      "Epoch 00151 |  Loss 0.6791\n",
      "Epoch 00152 |  Loss 0.6790\n",
      "Epoch 00153 |  Loss 0.6787\n",
      "Epoch 00154 |  Loss 0.6788\n",
      "Epoch 00155 |  Loss 0.6785\n",
      "Epoch 00156 |  Loss 0.6778\n",
      "Epoch 00157 |  Loss 0.6779\n",
      "Epoch 00158 |  Loss 0.6777\n",
      "Epoch 00159 |  Loss 0.6774\n",
      "Epoch 00160 |  Loss 0.6770\n",
      "Epoch 00161 |  Loss 0.6774\n",
      "Epoch 00162 |  Loss 0.6770\n",
      "Epoch 00163 |  Loss 0.6773\n",
      "Epoch 00164 |  Loss 0.6767\n",
      "Epoch 00165 |  Loss 0.6766\n",
      "Epoch 00166 |  Loss 0.6767\n",
      "Epoch 00167 |  Loss 0.6769\n",
      "Epoch 00168 |  Loss 0.6762\n",
      "Epoch 00169 |  Loss 0.6757\n",
      "Epoch 00170 |  Loss 0.6755\n",
      "Epoch 00171 |  Loss 0.6755\n",
      "Epoch 00172 |  Loss 0.6757\n",
      "Epoch 00173 |  Loss 0.6754\n",
      "Epoch 00174 |  Loss 0.6753\n",
      "Epoch 00175 |  Loss 0.6749\n",
      "Epoch 00176 |  Loss 0.6749\n",
      "Epoch 00177 |  Loss 0.6748\n",
      "Epoch 00178 |  Loss 0.6745\n",
      "Epoch 00179 |  Loss 0.6745\n",
      "Epoch 00180 |  Loss 0.6747\n",
      "Epoch 00181 |  Loss 0.6742\n",
      "Epoch 00182 |  Loss 0.6740\n",
      "Epoch 00183 |  Loss 0.6743\n",
      "Epoch 00184 |  Loss 0.6740\n",
      "Epoch 00185 |  Loss 0.6741\n",
      "Epoch 00186 |  Loss 0.6734\n",
      "Epoch 00187 |  Loss 0.6739\n",
      "Epoch 00188 |  Loss 0.6739\n",
      "Epoch 00189 |  Loss 0.6737\n",
      "Epoch 00190 |  Loss 0.6731\n",
      "Epoch 00191 |  Loss 0.6733\n",
      "Epoch 00192 |  Loss 0.6731\n",
      "Epoch 00193 |  Loss 0.6732\n",
      "Epoch 00194 |  Loss 0.6732\n",
      "Epoch 00195 |  Loss 0.6734\n",
      "Epoch 00196 |  Loss 0.6728\n",
      "Epoch 00197 |  Loss 0.6725\n",
      "Epoch 00198 |  Loss 0.6727\n",
      "Epoch 00199 |  Loss 0.6728\n",
      "Epoch 00200 |  Loss 0.6726\n",
      "Epoch 00201 |  Loss 0.6722\n",
      "Epoch 00202 |  Loss 0.6730\n",
      "Epoch 00203 |  Loss 0.6722\n",
      "Epoch 00204 |  Loss 0.6721\n",
      "Epoch 00205 |  Loss 0.6723\n",
      "Epoch 00206 |  Loss 0.6721\n",
      "Epoch 00207 |  Loss 0.6725\n",
      "Epoch 00208 |  Loss 0.6719\n",
      "Epoch 00209 |  Loss 0.6718\n",
      "Epoch 00210 |  Loss 0.6717\n",
      "Epoch 00211 |  Loss 0.6718\n",
      "Epoch 00212 |  Loss 0.6718\n",
      "Epoch 00213 |  Loss 0.6715\n",
      "Epoch 00214 |  Loss 0.6715\n",
      "Epoch 00215 |  Loss 0.6719\n",
      "Epoch 00216 |  Loss 0.6717\n",
      "Epoch 00217 |  Loss 0.6715\n",
      "Epoch 00218 |  Loss 0.6715\n",
      "Epoch 00219 |  Loss 0.6713\n",
      "Epoch 00220 |  Loss 0.6712\n",
      "Epoch 00221 |  Loss 0.6715\n",
      "Epoch 00222 |  Loss 0.6715\n",
      "Epoch 00223 |  Loss 0.6716\n",
      "Epoch 00224 |  Loss 0.6709\n",
      "Epoch 00225 |  Loss 0.6710\n",
      "Epoch 00226 |  Loss 0.6708\n",
      "Epoch 00227 |  Loss 0.6709\n",
      "Epoch 00228 |  Loss 0.6708\n",
      "Epoch 00229 |  Loss 0.6708\n",
      "Epoch 00230 |  Loss 0.6707\n",
      "Epoch 00231 |  Loss 0.6708\n",
      "Epoch 00232 |  Loss 0.6706\n",
      "Epoch 00233 |  Loss 0.6710\n",
      "Epoch 00234 |  Loss 0.6702\n",
      "Epoch 00235 |  Loss 0.6708\n",
      "Epoch 00236 |  Loss 0.6704\n",
      "Epoch 00237 |  Loss 0.6706\n",
      "Epoch 00238 |  Loss 0.6706\n",
      "Epoch 00239 |  Loss 0.6708\n",
      "Epoch 00240 |  Loss 0.6705\n",
      "Epoch 00241 |  Loss 0.6703\n",
      "Epoch 00242 |  Loss 0.6702\n",
      "Epoch 00243 |  Loss 0.6702\n",
      "Epoch 00244 |  Loss 0.6699\n",
      "Epoch 00245 |  Loss 0.6703\n",
      "Epoch 00246 |  Loss 0.6699\n",
      "Epoch 00247 |  Loss 0.6701\n",
      "Epoch 00248 |  Loss 0.6703\n",
      "Epoch 00249 |  Loss 0.6696\n",
      "Epoch 00250 |  Loss 0.6700\n",
      "Epoch 00251 |  Loss 0.6701\n",
      "Epoch 00252 |  Loss 0.6700\n",
      "Epoch 00253 |  Loss 0.6694\n",
      "Epoch 00254 |  Loss 0.6697\n",
      "Epoch 00255 |  Loss 0.6698\n",
      "Epoch 00256 |  Loss 0.6697\n",
      "Epoch 00257 |  Loss 0.6696\n",
      "Epoch 00258 |  Loss 0.6700\n",
      "Epoch 00259 |  Loss 0.6695\n",
      "Epoch 00260 |  Loss 0.6696\n",
      "Epoch 00261 |  Loss 0.6693\n",
      "Epoch 00262 |  Loss 0.6690\n",
      "Epoch 00263 |  Loss 0.6689\n",
      "Epoch 00264 |  Loss 0.6690\n",
      "Epoch 00265 |  Loss 0.6694\n",
      "Epoch 00266 |  Loss 0.6697\n",
      "Epoch 00267 |  Loss 0.6691\n",
      "Epoch 00268 |  Loss 0.6692\n",
      "Epoch 00269 |  Loss 0.6693\n",
      "Epoch 00270 |  Loss 0.6693\n",
      "Epoch 00271 |  Loss 0.6693\n",
      "Epoch 00272 |  Loss 0.6692\n",
      "Epoch 00273 |  Loss 0.6691\n",
      "Epoch 00274 |  Loss 0.6684\n",
      "Epoch 00275 |  Loss 0.6690\n",
      "Epoch 00276 |  Loss 0.6686\n",
      "Epoch 00277 |  Loss 0.6689\n",
      "Epoch 00278 |  Loss 0.6685\n",
      "Epoch 00279 |  Loss 0.6685\n",
      "Epoch 00280 |  Loss 0.6682\n",
      "Epoch 00281 |  Loss 0.6687\n",
      "Epoch 00282 |  Loss 0.6685\n",
      "Epoch 00283 |  Loss 0.6685\n",
      "Epoch 00284 |  Loss 0.6684\n",
      "Epoch 00285 |  Loss 0.6685\n",
      "Epoch 00286 |  Loss 0.6681\n",
      "Epoch 00287 |  Loss 0.6687\n",
      "Epoch 00288 |  Loss 0.6685\n",
      "Epoch 00289 |  Loss 0.6687\n",
      "Epoch 00290 |  Loss 0.6684\n",
      "Epoch 00291 |  Loss 0.6685\n",
      "Epoch 00292 |  Loss 0.6684\n",
      "Epoch 00293 |  Loss 0.6685\n",
      "Epoch 00294 |  Loss 0.6681\n",
      "Epoch 00295 |  Loss 0.6682\n",
      "Epoch 00296 |  Loss 0.6683\n",
      "Epoch 00297 |  Loss 0.6678\n",
      "Epoch 00298 |  Loss 0.6680\n",
      "Epoch 00299 |  Loss 0.6685\n",
      "Epoch 00300 |  Loss 0.6677\n",
      "Epoch 00301 |  Loss 0.6678\n",
      "Epoch 00302 |  Loss 0.6680\n",
      "Epoch 00303 |  Loss 0.6679\n",
      "Epoch 00304 |  Loss 0.6676\n",
      "Epoch 00305 |  Loss 0.6684\n",
      "Epoch 00306 |  Loss 0.6676\n",
      "Epoch 00307 |  Loss 0.6677\n",
      "Epoch 00308 |  Loss 0.6681\n",
      "Epoch 00309 |  Loss 0.6678\n",
      "Epoch 00310 |  Loss 0.6675\n",
      "Epoch 00311 |  Loss 0.6675\n",
      "Epoch 00312 |  Loss 0.6674\n",
      "Epoch 00313 |  Loss 0.6675\n",
      "Epoch 00314 |  Loss 0.6675\n",
      "Epoch 00315 |  Loss 0.6674\n",
      "Epoch 00316 |  Loss 0.6681\n",
      "Epoch 00317 |  Loss 0.6672\n",
      "Epoch 00318 |  Loss 0.6677\n",
      "Epoch 00319 |  Loss 0.6673\n",
      "Epoch 00320 |  Loss 0.6676\n",
      "Epoch 00321 |  Loss 0.6675\n",
      "Epoch 00322 |  Loss 0.6675\n",
      "Epoch 00323 |  Loss 0.6672\n",
      "Epoch 00324 |  Loss 0.6675\n",
      "Epoch 00325 |  Loss 0.6670\n",
      "Epoch 00326 |  Loss 0.6673\n",
      "Epoch 00327 |  Loss 0.6673\n",
      "Epoch 00328 |  Loss 0.6667\n",
      "Epoch 00329 |  Loss 0.6670\n",
      "Epoch 00330 |  Loss 0.6669\n",
      "Epoch 00331 |  Loss 0.6673\n",
      "Epoch 00332 |  Loss 0.6669\n",
      "Epoch 00333 |  Loss 0.6669\n",
      "Epoch 00334 |  Loss 0.6668\n",
      "Epoch 00335 |  Loss 0.6670\n",
      "Epoch 00336 |  Loss 0.6666\n",
      "Epoch 00337 |  Loss 0.6666\n",
      "Epoch 00338 |  Loss 0.6667\n",
      "Epoch 00339 |  Loss 0.6668\n",
      "Epoch 00340 |  Loss 0.6669\n",
      "Epoch 00341 |  Loss 0.6665\n",
      "Epoch 00342 |  Loss 0.6666\n",
      "Epoch 00343 |  Loss 0.6665\n",
      "Epoch 00344 |  Loss 0.6661\n",
      "Epoch 00345 |  Loss 0.6666\n",
      "Epoch 00346 |  Loss 0.6662\n",
      "Epoch 00347 |  Loss 0.6668\n",
      "Epoch 00348 |  Loss 0.6664\n",
      "Epoch 00349 |  Loss 0.6664\n",
      "Epoch 00350 |  Loss 0.6661\n",
      "Epoch 00351 |  Loss 0.6666\n",
      "Epoch 00352 |  Loss 0.6659\n",
      "Epoch 00353 |  Loss 0.6660\n",
      "Epoch 00354 |  Loss 0.6665\n",
      "Epoch 00355 |  Loss 0.6665\n",
      "Epoch 00356 |  Loss 0.6660\n",
      "Epoch 00357 |  Loss 0.6662\n",
      "Epoch 00358 |  Loss 0.6665\n",
      "Epoch 00359 |  Loss 0.6657\n",
      "Epoch 00360 |  Loss 0.6663\n",
      "Epoch 00361 |  Loss 0.6660\n",
      "Epoch 00362 |  Loss 0.6659\n",
      "Epoch 00363 |  Loss 0.6660\n",
      "Epoch 00364 |  Loss 0.6659\n",
      "Epoch 00365 |  Loss 0.6661\n",
      "Epoch 00366 |  Loss 0.6661\n",
      "Epoch 00367 |  Loss 0.6658\n",
      "Epoch 00368 |  Loss 0.6657\n",
      "Epoch 00369 |  Loss 0.6656\n",
      "Epoch 00370 |  Loss 0.6658\n",
      "Epoch 00371 |  Loss 0.6661\n",
      "Epoch 00372 |  Loss 0.6658\n",
      "Epoch 00373 |  Loss 0.6656\n",
      "Epoch 00374 |  Loss 0.6661\n",
      "Epoch 00375 |  Loss 0.6660\n",
      "Epoch 00376 |  Loss 0.6658\n",
      "Epoch 00377 |  Loss 0.6658\n",
      "Epoch 00378 |  Loss 0.6655\n",
      "Epoch 00379 |  Loss 0.6656\n",
      "Epoch 00380 |  Loss 0.6654\n",
      "Epoch 00381 |  Loss 0.6657\n",
      "Epoch 00382 |  Loss 0.6654\n",
      "Epoch 00383 |  Loss 0.6654\n",
      "Epoch 00384 |  Loss 0.6653\n",
      "Epoch 00385 |  Loss 0.6653\n",
      "Epoch 00386 |  Loss 0.6651\n",
      "Epoch 00387 |  Loss 0.6649\n",
      "Epoch 00388 |  Loss 0.6654\n",
      "Epoch 00389 |  Loss 0.6653\n",
      "Epoch 00390 |  Loss 0.6653\n",
      "Epoch 00391 |  Loss 0.6649\n",
      "Epoch 00392 |  Loss 0.6652\n",
      "Epoch 00393 |  Loss 0.6652\n",
      "Epoch 00394 |  Loss 0.6652\n",
      "Epoch 00395 |  Loss 0.6649\n",
      "Epoch 00396 |  Loss 0.6652\n",
      "Epoch 00397 |  Loss 0.6643\n",
      "Epoch 00398 |  Loss 0.6651\n",
      "Epoch 00399 |  Loss 0.6652\n",
      "Epoch 00400 |  Loss 0.6648\n",
      "Epoch 00401 |  Loss 0.6652\n",
      "Epoch 00402 |  Loss 0.6652\n",
      "Epoch 00403 |  Loss 0.6646\n",
      "Epoch 00404 |  Loss 0.6646\n",
      "Epoch 00405 |  Loss 0.6646\n",
      "Epoch 00406 |  Loss 0.6645\n",
      "Epoch 00407 |  Loss 0.6651\n",
      "Epoch 00408 |  Loss 0.6646\n",
      "Epoch 00409 |  Loss 0.6647\n",
      "Epoch 00410 |  Loss 0.6647\n",
      "Epoch 00411 |  Loss 0.6642\n",
      "Epoch 00412 |  Loss 0.6648\n",
      "Epoch 00413 |  Loss 0.6648\n",
      "Epoch 00414 |  Loss 0.6650\n",
      "Epoch 00415 |  Loss 0.6645\n",
      "Epoch 00416 |  Loss 0.6647\n",
      "Epoch 00417 |  Loss 0.6644\n",
      "Epoch 00418 |  Loss 0.6644\n",
      "Epoch 00419 |  Loss 0.6646\n",
      "Epoch 00420 |  Loss 0.6648\n",
      "Epoch 00421 |  Loss 0.6638\n",
      "Epoch 00422 |  Loss 0.6640\n",
      "Epoch 00423 |  Loss 0.6643\n",
      "Epoch 00424 |  Loss 0.6644\n",
      "Epoch 00425 |  Loss 0.6641\n",
      "Epoch 00426 |  Loss 0.6645\n",
      "Epoch 00427 |  Loss 0.6644\n",
      "Epoch 00428 |  Loss 0.6638\n",
      "Epoch 00429 |  Loss 0.6643\n",
      "Epoch 00430 |  Loss 0.6642\n",
      "Epoch 00431 |  Loss 0.6641\n",
      "Epoch 00432 |  Loss 0.6640\n",
      "Epoch 00433 |  Loss 0.6638\n",
      "Epoch 00434 |  Loss 0.6641\n",
      "Epoch 00435 |  Loss 0.6638\n",
      "Epoch 00436 |  Loss 0.6640\n",
      "Epoch 00437 |  Loss 0.6643\n",
      "Epoch 00438 |  Loss 0.6637\n",
      "Epoch 00439 |  Loss 0.6637\n",
      "Epoch 00440 |  Loss 0.6634\n",
      "Epoch 00441 |  Loss 0.6639\n",
      "Epoch 00442 |  Loss 0.6637\n",
      "Epoch 00443 |  Loss 0.6641\n",
      "Epoch 00444 |  Loss 0.6638\n",
      "Epoch 00445 |  Loss 0.6642\n",
      "Epoch 00446 |  Loss 0.6638\n",
      "Epoch 00447 |  Loss 0.6638\n",
      "Epoch 00448 |  Loss 0.6638\n",
      "Epoch 00449 |  Loss 0.6639\n",
      "Epoch 00450 |  Loss 0.6636\n",
      "Epoch 00451 |  Loss 0.6637\n",
      "Epoch 00452 |  Loss 0.6638\n",
      "Epoch 00453 |  Loss 0.6637\n",
      "Epoch 00454 |  Loss 0.6637\n",
      "Epoch 00455 |  Loss 0.6635\n",
      "Epoch 00456 |  Loss 0.6633\n",
      "Epoch 00457 |  Loss 0.6636\n",
      "Epoch 00458 |  Loss 0.6632\n",
      "Epoch 00459 |  Loss 0.6631\n",
      "Epoch 00460 |  Loss 0.6631\n",
      "Epoch 00461 |  Loss 0.6636\n",
      "Epoch 00462 |  Loss 0.6635\n",
      "Epoch 00463 |  Loss 0.6636\n",
      "Epoch 00464 |  Loss 0.6630\n",
      "Epoch 00465 |  Loss 0.6631\n",
      "Epoch 00466 |  Loss 0.6632\n",
      "Epoch 00467 |  Loss 0.6629\n",
      "Epoch 00468 |  Loss 0.6632\n",
      "Epoch 00469 |  Loss 0.6634\n",
      "Epoch 00470 |  Loss 0.6628\n",
      "Epoch 00471 |  Loss 0.6631\n",
      "Epoch 00472 |  Loss 0.6636\n",
      "Epoch 00473 |  Loss 0.6629\n",
      "Epoch 00474 |  Loss 0.6631\n",
      "Epoch 00475 |  Loss 0.6632\n",
      "Epoch 00476 |  Loss 0.6632\n",
      "Epoch 00477 |  Loss 0.6632\n",
      "Epoch 00478 |  Loss 0.6634\n",
      "Epoch 00479 |  Loss 0.6629\n",
      "Epoch 00480 |  Loss 0.6630\n",
      "Epoch 00481 |  Loss 0.6631\n",
      "Epoch 00482 |  Loss 0.6626\n",
      "Epoch 00483 |  Loss 0.6623\n",
      "Epoch 00484 |  Loss 0.6627\n",
      "Epoch 00485 |  Loss 0.6633\n",
      "Epoch 00486 |  Loss 0.6626\n",
      "Epoch 00487 |  Loss 0.6629\n",
      "Epoch 00488 |  Loss 0.6624\n",
      "Epoch 00489 |  Loss 0.6626\n",
      "Epoch 00490 |  Loss 0.6627\n",
      "Epoch 00491 |  Loss 0.6630\n",
      "Epoch 00492 |  Loss 0.6628\n",
      "Epoch 00493 |  Loss 0.6622\n",
      "Epoch 00494 |  Loss 0.6621\n",
      "Epoch 00495 |  Loss 0.6625\n",
      "Epoch 00496 |  Loss 0.6628\n",
      "Epoch 00497 |  Loss 0.6629\n",
      "Epoch 00498 |  Loss 0.6624\n",
      "Epoch 00499 |  Loss 0.6621\n",
      "Epoch 00500 |  Loss 0.6624\n",
      "Epoch 00501 |  Loss 0.6620\n",
      "Epoch 00502 |  Loss 0.6620\n",
      "Epoch 00503 |  Loss 0.6623\n",
      "Epoch 00504 |  Loss 0.6620\n",
      "Epoch 00505 |  Loss 0.6624\n",
      "Epoch 00506 |  Loss 0.6626\n",
      "Epoch 00507 |  Loss 0.6620\n",
      "Epoch 00508 |  Loss 0.6625\n",
      "Epoch 00509 |  Loss 0.6623\n",
      "Epoch 00510 |  Loss 0.6622\n",
      "Epoch 00511 |  Loss 0.6620\n",
      "Epoch 00512 |  Loss 0.6622\n",
      "Epoch 00513 |  Loss 0.6625\n",
      "Epoch 00514 |  Loss 0.6622\n",
      "Epoch 00515 |  Loss 0.6620\n",
      "Epoch 00516 |  Loss 0.6618\n",
      "Epoch 00517 |  Loss 0.6619\n",
      "Epoch 00518 |  Loss 0.6618\n",
      "Epoch 00519 |  Loss 0.6617\n",
      "Epoch 00520 |  Loss 0.6620\n",
      "Epoch 00521 |  Loss 0.6620\n",
      "Epoch 00522 |  Loss 0.6618\n",
      "Epoch 00523 |  Loss 0.6620\n",
      "Epoch 00524 |  Loss 0.6618\n",
      "Epoch 00525 |  Loss 0.6616\n",
      "Epoch 00526 |  Loss 0.6619\n",
      "Epoch 00527 |  Loss 0.6618\n",
      "Epoch 00528 |  Loss 0.6616\n",
      "Epoch 00529 |  Loss 0.6614\n",
      "Epoch 00530 |  Loss 0.6622\n",
      "Epoch 00531 |  Loss 0.6614\n",
      "Epoch 00532 |  Loss 0.6613\n",
      "Epoch 00533 |  Loss 0.6617\n",
      "Epoch 00534 |  Loss 0.6616\n",
      "Epoch 00535 |  Loss 0.6616\n",
      "Epoch 00536 |  Loss 0.6612\n",
      "Epoch 00537 |  Loss 0.6618\n",
      "Epoch 00538 |  Loss 0.6618\n",
      "Epoch 00539 |  Loss 0.6615\n",
      "Epoch 00540 |  Loss 0.6613\n",
      "Epoch 00541 |  Loss 0.6612\n",
      "Epoch 00542 |  Loss 0.6615\n",
      "Epoch 00543 |  Loss 0.6615\n",
      "Epoch 00544 |  Loss 0.6613\n",
      "Epoch 00545 |  Loss 0.6610\n",
      "Epoch 00546 |  Loss 0.6613\n",
      "Epoch 00547 |  Loss 0.6617\n",
      "Epoch 00548 |  Loss 0.6614\n",
      "Epoch 00549 |  Loss 0.6616\n",
      "Epoch 00550 |  Loss 0.6614\n",
      "Epoch 00551 |  Loss 0.6613\n",
      "Epoch 00552 |  Loss 0.6613\n",
      "Epoch 00553 |  Loss 0.6614\n",
      "Epoch 00554 |  Loss 0.6616\n",
      "Epoch 00555 |  Loss 0.6613\n",
      "Epoch 00556 |  Loss 0.6611\n",
      "Epoch 00557 |  Loss 0.6612\n",
      "Epoch 00558 |  Loss 0.6613\n",
      "Epoch 00559 |  Loss 0.6604\n",
      "Epoch 00560 |  Loss 0.6611\n",
      "Epoch 00561 |  Loss 0.6612\n",
      "Epoch 00562 |  Loss 0.6607\n",
      "Epoch 00563 |  Loss 0.6609\n",
      "Epoch 00564 |  Loss 0.6612\n",
      "Epoch 00565 |  Loss 0.6610\n",
      "Epoch 00566 |  Loss 0.6610\n",
      "Epoch 00567 |  Loss 0.6612\n",
      "Epoch 00568 |  Loss 0.6611\n",
      "Epoch 00569 |  Loss 0.6607\n",
      "Epoch 00570 |  Loss 0.6611\n",
      "Epoch 00571 |  Loss 0.6608\n",
      "Epoch 00572 |  Loss 0.6610\n",
      "Epoch 00573 |  Loss 0.6608\n",
      "Epoch 00574 |  Loss 0.6607\n",
      "Epoch 00575 |  Loss 0.6609\n",
      "Epoch 00576 |  Loss 0.6611\n",
      "Epoch 00577 |  Loss 0.6604\n",
      "Epoch 00578 |  Loss 0.6601\n",
      "Epoch 00579 |  Loss 0.6611\n",
      "Epoch 00580 |  Loss 0.6607\n",
      "Epoch 00581 |  Loss 0.6606\n",
      "Epoch 00582 |  Loss 0.6605\n",
      "Epoch 00583 |  Loss 0.6611\n",
      "Epoch 00584 |  Loss 0.6610\n",
      "Epoch 00585 |  Loss 0.6602\n",
      "Epoch 00586 |  Loss 0.6610\n",
      "Epoch 00587 |  Loss 0.6607\n",
      "Epoch 00588 |  Loss 0.6602\n",
      "Epoch 00589 |  Loss 0.6606\n",
      "Epoch 00590 |  Loss 0.6611\n",
      "Epoch 00591 |  Loss 0.6605\n",
      "Epoch 00592 |  Loss 0.6603\n",
      "Epoch 00593 |  Loss 0.6604\n",
      "Epoch 00594 |  Loss 0.6605\n",
      "Epoch 00595 |  Loss 0.6602\n",
      "Epoch 00596 |  Loss 0.6606\n",
      "Epoch 00597 |  Loss 0.6600\n",
      "Epoch 00598 |  Loss 0.6605\n",
      "Epoch 00599 |  Loss 0.6600\n",
      "Epoch 00600 |  Loss 0.6603\n",
      "Epoch 00601 |  Loss 0.6601\n",
      "Epoch 00602 |  Loss 0.6606\n",
      "Epoch 00603 |  Loss 0.6603\n",
      "Epoch 00604 |  Loss 0.6602\n",
      "Epoch 00605 |  Loss 0.6602\n",
      "Epoch 00606 |  Loss 0.6600\n",
      "Epoch 00607 |  Loss 0.6604\n",
      "Epoch 00608 |  Loss 0.6601\n",
      "Epoch 00609 |  Loss 0.6601\n",
      "Epoch 00610 |  Loss 0.6600\n",
      "Epoch 00611 |  Loss 0.6597\n",
      "Epoch 00612 |  Loss 0.6601\n",
      "Epoch 00613 |  Loss 0.6604\n",
      "Epoch 00614 |  Loss 0.6599\n",
      "Epoch 00615 |  Loss 0.6602\n",
      "Epoch 00616 |  Loss 0.6604\n",
      "Epoch 00617 |  Loss 0.6596\n",
      "Epoch 00618 |  Loss 0.6599\n",
      "Epoch 00619 |  Loss 0.6598\n",
      "Epoch 00620 |  Loss 0.6602\n",
      "Epoch 00621 |  Loss 0.6600\n",
      "Epoch 00622 |  Loss 0.6599\n",
      "Epoch 00623 |  Loss 0.6597\n",
      "Epoch 00624 |  Loss 0.6601\n",
      "Epoch 00625 |  Loss 0.6601\n",
      "Epoch 00626 |  Loss 0.6598\n",
      "Epoch 00627 |  Loss 0.6598\n",
      "Epoch 00628 |  Loss 0.6600\n",
      "Epoch 00629 |  Loss 0.6596\n",
      "Epoch 00630 |  Loss 0.6601\n",
      "Epoch 00631 |  Loss 0.6598\n",
      "Epoch 00632 |  Loss 0.6601\n",
      "Epoch 00633 |  Loss 0.6595\n",
      "Epoch 00634 |  Loss 0.6599\n",
      "Epoch 00635 |  Loss 0.6595\n",
      "Epoch 00636 |  Loss 0.6594\n",
      "Epoch 00637 |  Loss 0.6600\n",
      "Epoch 00638 |  Loss 0.6596\n",
      "Epoch 00639 |  Loss 0.6600\n",
      "Epoch 00640 |  Loss 0.6593\n",
      "Epoch 00641 |  Loss 0.6594\n",
      "Epoch 00642 |  Loss 0.6592\n",
      "Epoch 00643 |  Loss 0.6596\n",
      "Epoch 00644 |  Loss 0.6592\n",
      "Epoch 00645 |  Loss 0.6596\n",
      "Epoch 00646 |  Loss 0.6596\n",
      "Epoch 00647 |  Loss 0.6596\n",
      "Epoch 00648 |  Loss 0.6591\n",
      "Epoch 00649 |  Loss 0.6594\n",
      "Epoch 00650 |  Loss 0.6594\n",
      "Epoch 00651 |  Loss 0.6596\n",
      "Epoch 00652 |  Loss 0.6590\n",
      "Epoch 00653 |  Loss 0.6595\n",
      "Epoch 00654 |  Loss 0.6598\n",
      "Epoch 00655 |  Loss 0.6592\n",
      "Epoch 00656 |  Loss 0.6594\n",
      "Epoch 00657 |  Loss 0.6600\n",
      "Epoch 00658 |  Loss 0.6599\n",
      "Epoch 00659 |  Loss 0.6595\n",
      "Epoch 00660 |  Loss 0.6594\n",
      "Epoch 00661 |  Loss 0.6596\n",
      "Epoch 00662 |  Loss 0.6588\n",
      "Epoch 00663 |  Loss 0.6595\n",
      "Epoch 00664 |  Loss 0.6590\n",
      "Epoch 00665 |  Loss 0.6591\n",
      "Epoch 00666 |  Loss 0.6589\n",
      "Epoch 00667 |  Loss 0.6593\n",
      "Epoch 00668 |  Loss 0.6590\n",
      "Epoch 00669 |  Loss 0.6587\n",
      "Epoch 00670 |  Loss 0.6592\n",
      "Epoch 00671 |  Loss 0.6590\n",
      "Epoch 00672 |  Loss 0.6594\n",
      "Epoch 00673 |  Loss 0.6591\n",
      "Epoch 00674 |  Loss 0.6591\n",
      "Epoch 00675 |  Loss 0.6588\n",
      "Epoch 00676 |  Loss 0.6590\n",
      "Epoch 00677 |  Loss 0.6589\n",
      "Epoch 00678 |  Loss 0.6589\n",
      "Epoch 00679 |  Loss 0.6589\n",
      "Epoch 00680 |  Loss 0.6591\n",
      "Epoch 00681 |  Loss 0.6591\n",
      "Epoch 00682 |  Loss 0.6589\n",
      "Epoch 00683 |  Loss 0.6586\n",
      "Epoch 00684 |  Loss 0.6587\n",
      "Epoch 00685 |  Loss 0.6592\n",
      "Epoch 00686 |  Loss 0.6595\n",
      "Epoch 00687 |  Loss 0.6589\n",
      "Epoch 00688 |  Loss 0.6585\n",
      "Epoch 00689 |  Loss 0.6587\n",
      "Epoch 00690 |  Loss 0.6589\n",
      "Epoch 00691 |  Loss 0.6587\n",
      "Epoch 00692 |  Loss 0.6586\n",
      "Epoch 00693 |  Loss 0.6589\n",
      "Epoch 00694 |  Loss 0.6590\n",
      "Epoch 00695 |  Loss 0.6583\n",
      "Epoch 00696 |  Loss 0.6584\n",
      "Epoch 00697 |  Loss 0.6587\n",
      "Epoch 00698 |  Loss 0.6587\n",
      "Epoch 00699 |  Loss 0.6584\n",
      "Epoch 00700 |  Loss 0.6585\n",
      "Epoch 00701 |  Loss 0.6582\n",
      "Epoch 00702 |  Loss 0.6587\n",
      "Epoch 00703 |  Loss 0.6586\n",
      "Epoch 00704 |  Loss 0.6585\n",
      "Epoch 00705 |  Loss 0.6584\n",
      "Epoch 00706 |  Loss 0.6584\n",
      "Epoch 00707 |  Loss 0.6586\n",
      "Epoch 00708 |  Loss 0.6583\n",
      "Epoch 00709 |  Loss 0.6583\n",
      "Epoch 00710 |  Loss 0.6587\n",
      "Epoch 00711 |  Loss 0.6585\n",
      "Epoch 00712 |  Loss 0.6582\n",
      "Epoch 00713 |  Loss 0.6582\n",
      "Epoch 00714 |  Loss 0.6582\n",
      "Epoch 00715 |  Loss 0.6587\n",
      "Epoch 00716 |  Loss 0.6582\n",
      "Epoch 00717 |  Loss 0.6581\n",
      "Epoch 00718 |  Loss 0.6586\n",
      "Epoch 00719 |  Loss 0.6586\n",
      "Epoch 00720 |  Loss 0.6586\n",
      "Epoch 00721 |  Loss 0.6580\n",
      "Epoch 00722 |  Loss 0.6580\n",
      "Epoch 00723 |  Loss 0.6581\n",
      "Epoch 00724 |  Loss 0.6579\n",
      "Epoch 00725 |  Loss 0.6577\n",
      "Epoch 00726 |  Loss 0.6583\n",
      "Epoch 00727 |  Loss 0.6580\n",
      "Epoch 00728 |  Loss 0.6582\n",
      "Epoch 00729 |  Loss 0.6579\n",
      "Epoch 00730 |  Loss 0.6582\n",
      "Epoch 00731 |  Loss 0.6585\n",
      "Epoch 00732 |  Loss 0.6580\n",
      "Epoch 00733 |  Loss 0.6580\n",
      "Epoch 00734 |  Loss 0.6580\n",
      "Epoch 00735 |  Loss 0.6584\n",
      "Epoch 00736 |  Loss 0.6583\n",
      "Epoch 00737 |  Loss 0.6584\n",
      "Epoch 00738 |  Loss 0.6583\n",
      "Epoch 00739 |  Loss 0.6578\n",
      "Epoch 00740 |  Loss 0.6579\n",
      "Epoch 00741 |  Loss 0.6576\n",
      "Epoch 00742 |  Loss 0.6580\n",
      "Epoch 00743 |  Loss 0.6581\n",
      "Epoch 00744 |  Loss 0.6575\n",
      "Epoch 00745 |  Loss 0.6581\n",
      "Epoch 00746 |  Loss 0.6579\n",
      "Epoch 00747 |  Loss 0.6576\n",
      "Epoch 00748 |  Loss 0.6575\n",
      "Epoch 00749 |  Loss 0.6576\n",
      "Epoch 00750 |  Loss 0.6583\n",
      "Epoch 00751 |  Loss 0.6577\n",
      "Epoch 00752 |  Loss 0.6583\n",
      "Epoch 00753 |  Loss 0.6583\n",
      "Epoch 00754 |  Loss 0.6582\n",
      "Epoch 00755 |  Loss 0.6575\n",
      "Epoch 00756 |  Loss 0.6576\n",
      "Epoch 00757 |  Loss 0.6574\n",
      "Epoch 00758 |  Loss 0.6579\n",
      "Epoch 00759 |  Loss 0.6576\n",
      "Epoch 00760 |  Loss 0.6574\n",
      "Epoch 00761 |  Loss 0.6578\n",
      "Epoch 00762 |  Loss 0.6578\n",
      "Epoch 00763 |  Loss 0.6576\n",
      "Epoch 00764 |  Loss 0.6574\n",
      "Epoch 00765 |  Loss 0.6575\n",
      "Epoch 00766 |  Loss 0.6580\n",
      "Epoch 00767 |  Loss 0.6576\n",
      "Epoch 00768 |  Loss 0.6574\n",
      "Epoch 00769 |  Loss 0.6573\n",
      "Epoch 00770 |  Loss 0.6573\n",
      "Epoch 00771 |  Loss 0.6573\n",
      "Epoch 00772 |  Loss 0.6575\n",
      "Epoch 00773 |  Loss 0.6579\n",
      "Epoch 00774 |  Loss 0.6576\n",
      "Epoch 00775 |  Loss 0.6574\n",
      "Epoch 00776 |  Loss 0.6577\n",
      "Epoch 00777 |  Loss 0.6573\n",
      "Epoch 00778 |  Loss 0.6575\n",
      "Epoch 00779 |  Loss 0.6579\n",
      "Epoch 00780 |  Loss 0.6573\n",
      "Epoch 00781 |  Loss 0.6571\n",
      "Epoch 00782 |  Loss 0.6572\n",
      "Epoch 00783 |  Loss 0.6571\n",
      "Epoch 00784 |  Loss 0.6576\n",
      "Epoch 00785 |  Loss 0.6571\n",
      "Epoch 00786 |  Loss 0.6571\n",
      "Epoch 00787 |  Loss 0.6569\n",
      "Epoch 00788 |  Loss 0.6577\n",
      "Epoch 00789 |  Loss 0.6578\n",
      "Epoch 00790 |  Loss 0.6575\n",
      "Epoch 00791 |  Loss 0.6575\n",
      "Epoch 00792 |  Loss 0.6571\n",
      "Epoch 00793 |  Loss 0.6574\n",
      "Epoch 00794 |  Loss 0.6572\n",
      "Epoch 00795 |  Loss 0.6574\n",
      "Epoch 00796 |  Loss 0.6570\n",
      "Epoch 00797 |  Loss 0.6569\n",
      "Epoch 00798 |  Loss 0.6573\n",
      "Epoch 00799 |  Loss 0.6571\n",
      "Epoch 00800 |  Loss 0.6573\n",
      "Epoch 00801 |  Loss 0.6568\n",
      "Epoch 00802 |  Loss 0.6569\n",
      "Epoch 00803 |  Loss 0.6568\n",
      "Epoch 00804 |  Loss 0.6575\n",
      "Epoch 00805 |  Loss 0.6571\n",
      "Epoch 00806 |  Loss 0.6571\n",
      "Epoch 00807 |  Loss 0.6573\n",
      "Epoch 00808 |  Loss 0.6566\n",
      "Epoch 00809 |  Loss 0.6572\n",
      "Epoch 00810 |  Loss 0.6575\n",
      "Epoch 00811 |  Loss 0.6573\n",
      "Epoch 00812 |  Loss 0.6568\n",
      "Epoch 00813 |  Loss 0.6569\n",
      "Epoch 00814 |  Loss 0.6569\n",
      "Epoch 00815 |  Loss 0.6570\n",
      "Epoch 00816 |  Loss 0.6570\n",
      "Epoch 00817 |  Loss 0.6565\n",
      "Epoch 00818 |  Loss 0.6568\n",
      "Epoch 00819 |  Loss 0.6570\n",
      "Epoch 00820 |  Loss 0.6569\n",
      "Epoch 00821 |  Loss 0.6569\n",
      "Epoch 00822 |  Loss 0.6569\n",
      "Epoch 00823 |  Loss 0.6569\n",
      "Epoch 00824 |  Loss 0.6568\n",
      "Epoch 00825 |  Loss 0.6568\n",
      "Epoch 00826 |  Loss 0.6567\n",
      "Epoch 00827 |  Loss 0.6567\n",
      "Epoch 00828 |  Loss 0.6569\n",
      "Epoch 00829 |  Loss 0.6566\n",
      "Epoch 00830 |  Loss 0.6564\n",
      "Epoch 00831 |  Loss 0.6567\n",
      "Epoch 00832 |  Loss 0.6570\n",
      "Epoch 00833 |  Loss 0.6567\n",
      "Epoch 00834 |  Loss 0.6566\n",
      "Epoch 00835 |  Loss 0.6568\n",
      "Epoch 00836 |  Loss 0.6565\n",
      "Epoch 00837 |  Loss 0.6563\n",
      "Epoch 00838 |  Loss 0.6567\n",
      "Epoch 00839 |  Loss 0.6567\n",
      "Epoch 00840 |  Loss 0.6563\n",
      "Epoch 00841 |  Loss 0.6569\n",
      "Epoch 00842 |  Loss 0.6565\n",
      "Epoch 00843 |  Loss 0.6566\n",
      "Epoch 00844 |  Loss 0.6568\n",
      "Epoch 00845 |  Loss 0.6560\n",
      "Epoch 00846 |  Loss 0.6566\n",
      "Epoch 00847 |  Loss 0.6565\n",
      "Epoch 00848 |  Loss 0.6569\n",
      "Epoch 00849 |  Loss 0.6557\n",
      "Epoch 00850 |  Loss 0.6564\n",
      "Epoch 00851 |  Loss 0.6566\n",
      "Epoch 00852 |  Loss 0.6565\n",
      "Epoch 00853 |  Loss 0.6564\n",
      "Epoch 00854 |  Loss 0.6562\n",
      "Epoch 00855 |  Loss 0.6566\n",
      "Epoch 00856 |  Loss 0.6564\n",
      "Epoch 00857 |  Loss 0.6566\n",
      "Epoch 00858 |  Loss 0.6567\n",
      "Epoch 00859 |  Loss 0.6568\n",
      "Epoch 00860 |  Loss 0.6564\n",
      "Epoch 00861 |  Loss 0.6562\n",
      "Epoch 00862 |  Loss 0.6562\n",
      "Epoch 00863 |  Loss 0.6561\n",
      "Epoch 00864 |  Loss 0.6561\n",
      "Epoch 00865 |  Loss 0.6561\n",
      "Epoch 00866 |  Loss 0.6560\n",
      "Epoch 00867 |  Loss 0.6563\n",
      "Epoch 00868 |  Loss 0.6563\n",
      "Epoch 00869 |  Loss 0.6564\n",
      "Epoch 00870 |  Loss 0.6562\n",
      "Epoch 00871 |  Loss 0.6559\n",
      "Epoch 00872 |  Loss 0.6561\n",
      "Epoch 00873 |  Loss 0.6560\n",
      "Epoch 00874 |  Loss 0.6559\n",
      "Epoch 00875 |  Loss 0.6557\n",
      "Epoch 00876 |  Loss 0.6562\n",
      "Epoch 00877 |  Loss 0.6560\n",
      "Epoch 00878 |  Loss 0.6560\n",
      "Epoch 00879 |  Loss 0.6565\n",
      "Epoch 00880 |  Loss 0.6560\n",
      "Epoch 00881 |  Loss 0.6559\n",
      "Epoch 00882 |  Loss 0.6564\n",
      "Epoch 00883 |  Loss 0.6561\n",
      "Epoch 00884 |  Loss 0.6559\n",
      "Epoch 00885 |  Loss 0.6565\n",
      "Epoch 00886 |  Loss 0.6555\n",
      "Epoch 00887 |  Loss 0.6558\n",
      "Epoch 00888 |  Loss 0.6559\n",
      "Epoch 00889 |  Loss 0.6558\n",
      "Epoch 00890 |  Loss 0.6555\n",
      "Epoch 00891 |  Loss 0.6563\n",
      "Epoch 00892 |  Loss 0.6559\n",
      "Epoch 00893 |  Loss 0.6563\n",
      "Epoch 00894 |  Loss 0.6558\n",
      "Epoch 00895 |  Loss 0.6561\n",
      "Epoch 00896 |  Loss 0.6559\n",
      "Epoch 00897 |  Loss 0.6555\n",
      "Epoch 00898 |  Loss 0.6561\n",
      "Epoch 00899 |  Loss 0.6563\n",
      "Epoch 00900 |  Loss 0.6557\n",
      "Epoch 00901 |  Loss 0.6555\n",
      "Epoch 00902 |  Loss 0.6555\n",
      "Epoch 00903 |  Loss 0.6558\n",
      "Epoch 00904 |  Loss 0.6560\n",
      "Epoch 00905 |  Loss 0.6562\n",
      "Epoch 00906 |  Loss 0.6556\n",
      "Epoch 00907 |  Loss 0.6558\n",
      "Epoch 00908 |  Loss 0.6558\n",
      "Epoch 00909 |  Loss 0.6557\n",
      "Epoch 00910 |  Loss 0.6563\n",
      "Epoch 00911 |  Loss 0.6556\n",
      "Epoch 00912 |  Loss 0.6556\n",
      "Epoch 00913 |  Loss 0.6559\n",
      "Epoch 00914 |  Loss 0.6556\n",
      "Epoch 00915 |  Loss 0.6565\n",
      "Epoch 00916 |  Loss 0.6558\n",
      "Epoch 00917 |  Loss 0.6555\n",
      "Epoch 00918 |  Loss 0.6557\n",
      "Epoch 00919 |  Loss 0.6557\n",
      "Epoch 00920 |  Loss 0.6554\n",
      "Epoch 00921 |  Loss 0.6554\n",
      "Epoch 00922 |  Loss 0.6558\n",
      "Epoch 00923 |  Loss 0.6556\n",
      "Epoch 00924 |  Loss 0.6555\n",
      "Epoch 00925 |  Loss 0.6554\n",
      "Epoch 00926 |  Loss 0.6555\n",
      "Epoch 00927 |  Loss 0.6554\n",
      "Epoch 00928 |  Loss 0.6556\n",
      "Epoch 00929 |  Loss 0.6552\n",
      "Epoch 00930 |  Loss 0.6555\n",
      "Epoch 00931 |  Loss 0.6557\n",
      "Epoch 00932 |  Loss 0.6558\n",
      "Epoch 00933 |  Loss 0.6552\n",
      "Epoch 00934 |  Loss 0.6554\n",
      "Epoch 00935 |  Loss 0.6555\n",
      "Epoch 00936 |  Loss 0.6555\n",
      "Epoch 00937 |  Loss 0.6557\n",
      "Epoch 00938 |  Loss 0.6556\n",
      "Epoch 00939 |  Loss 0.6554\n",
      "Epoch 00940 |  Loss 0.6555\n",
      "Epoch 00941 |  Loss 0.6554\n",
      "Epoch 00942 |  Loss 0.6552\n",
      "Epoch 00943 |  Loss 0.6552\n",
      "Epoch 00944 |  Loss 0.6553\n",
      "Epoch 00945 |  Loss 0.6552\n",
      "Epoch 00946 |  Loss 0.6558\n",
      "Epoch 00947 |  Loss 0.6557\n",
      "Epoch 00948 |  Loss 0.6552\n",
      "Epoch 00949 |  Loss 0.6556\n",
      "Epoch 00950 |  Loss 0.6552\n",
      "Epoch 00951 |  Loss 0.6553\n",
      "Epoch 00952 |  Loss 0.6553\n",
      "Epoch 00953 |  Loss 0.6554\n",
      "Epoch 00954 |  Loss 0.6550\n",
      "Epoch 00955 |  Loss 0.6553\n",
      "Epoch 00956 |  Loss 0.6550\n",
      "Epoch 00957 |  Loss 0.6553\n",
      "Epoch 00958 |  Loss 0.6549\n",
      "Epoch 00959 |  Loss 0.6549\n",
      "Epoch 00960 |  Loss 0.6549\n",
      "Epoch 00961 |  Loss 0.6551\n",
      "Epoch 00962 |  Loss 0.6554\n",
      "Epoch 00963 |  Loss 0.6550\n",
      "Epoch 00964 |  Loss 0.6552\n",
      "Epoch 00965 |  Loss 0.6547\n",
      "Epoch 00966 |  Loss 0.6552\n",
      "Epoch 00967 |  Loss 0.6546\n",
      "Epoch 00968 |  Loss 0.6547\n",
      "Epoch 00969 |  Loss 0.6553\n",
      "Epoch 00970 |  Loss 0.6550\n",
      "Epoch 00971 |  Loss 0.6549\n",
      "Epoch 00972 |  Loss 0.6552\n",
      "Epoch 00973 |  Loss 0.6545\n",
      "Epoch 00974 |  Loss 0.6556\n",
      "Epoch 00975 |  Loss 0.6553\n",
      "Epoch 00976 |  Loss 0.6550\n",
      "Epoch 00977 |  Loss 0.6548\n",
      "Epoch 00978 |  Loss 0.6548\n",
      "Epoch 00979 |  Loss 0.6547\n",
      "Epoch 00980 |  Loss 0.6546\n",
      "Epoch 00981 |  Loss 0.6553\n",
      "Epoch 00982 |  Loss 0.6550\n",
      "Epoch 00983 |  Loss 0.6550\n",
      "Epoch 00984 |  Loss 0.6552\n",
      "Epoch 00985 |  Loss 0.6545\n",
      "Epoch 00986 |  Loss 0.6549\n",
      "Epoch 00987 |  Loss 0.6547\n",
      "Epoch 00988 |  Loss 0.6543\n",
      "Epoch 00989 |  Loss 0.6545\n",
      "Epoch 00990 |  Loss 0.6547\n",
      "Epoch 00991 |  Loss 0.6545\n",
      "Epoch 00992 |  Loss 0.6544\n",
      "Epoch 00993 |  Loss 0.6549\n",
      "Epoch 00994 |  Loss 0.6547\n",
      "Epoch 00995 |  Loss 0.6544\n",
      "Epoch 00996 |  Loss 0.6549\n",
      "Epoch 00997 |  Loss 0.6550\n",
      "Epoch 00998 |  Loss 0.6549\n",
      "Epoch 00999 |  Loss 0.6549\n",
      "Epoch 01000 |  Loss 0.6547\n",
      "Epoch 01001 |  Loss 0.6548\n",
      "Epoch 01002 |  Loss 0.6547\n",
      "Epoch 01003 |  Loss 0.6547\n",
      "Epoch 01004 |  Loss 0.6549\n",
      "Epoch 01005 |  Loss 0.6546\n",
      "Epoch 01006 |  Loss 0.6546\n",
      "Epoch 01007 |  Loss 0.6548\n",
      "Epoch 01008 |  Loss 0.6541\n",
      "Epoch 01009 |  Loss 0.6542\n",
      "Epoch 01010 |  Loss 0.6547\n",
      "Epoch 01011 |  Loss 0.6544\n",
      "Epoch 01012 |  Loss 0.6537\n",
      "Epoch 01013 |  Loss 0.6550\n",
      "Epoch 01014 |  Loss 0.6550\n",
      "Epoch 01015 |  Loss 0.6543\n",
      "Epoch 01016 |  Loss 0.6548\n",
      "Epoch 01017 |  Loss 0.6550\n",
      "Epoch 01018 |  Loss 0.6547\n",
      "Epoch 01019 |  Loss 0.6544\n",
      "Epoch 01020 |  Loss 0.6547\n",
      "Epoch 01021 |  Loss 0.6544\n",
      "Epoch 01022 |  Loss 0.6543\n",
      "Epoch 01023 |  Loss 0.6541\n",
      "Epoch 01024 |  Loss 0.6548\n",
      "Epoch 01025 |  Loss 0.6544\n",
      "Epoch 01026 |  Loss 0.6540\n",
      "Epoch 01027 |  Loss 0.6542\n",
      "Epoch 01028 |  Loss 0.6545\n",
      "Epoch 01029 |  Loss 0.6543\n",
      "Epoch 01030 |  Loss 0.6546\n",
      "Epoch 01031 |  Loss 0.6540\n",
      "Epoch 01032 |  Loss 0.6544\n",
      "Epoch 01033 |  Loss 0.6544\n",
      "Epoch 01034 |  Loss 0.6541\n",
      "Epoch 01035 |  Loss 0.6543\n",
      "Epoch 01036 |  Loss 0.6544\n",
      "Epoch 01037 |  Loss 0.6538\n",
      "Epoch 01038 |  Loss 0.6541\n",
      "Epoch 01039 |  Loss 0.6542\n",
      "Epoch 01040 |  Loss 0.6540\n",
      "Epoch 01041 |  Loss 0.6540\n",
      "Epoch 01042 |  Loss 0.6545\n",
      "Epoch 01043 |  Loss 0.6543\n",
      "Epoch 01044 |  Loss 0.6548\n",
      "Epoch 01045 |  Loss 0.6539\n",
      "Epoch 01046 |  Loss 0.6537\n",
      "Epoch 01047 |  Loss 0.6538\n",
      "Epoch 01048 |  Loss 0.6542\n",
      "Epoch 01049 |  Loss 0.6538\n",
      "Epoch 01050 |  Loss 0.6537\n",
      "Epoch 01051 |  Loss 0.6540\n",
      "Epoch 01052 |  Loss 0.6541\n",
      "Epoch 01053 |  Loss 0.6540\n",
      "Epoch 01054 |  Loss 0.6541\n",
      "Epoch 01055 |  Loss 0.6546\n",
      "Epoch 01056 |  Loss 0.6545\n",
      "Epoch 01057 |  Loss 0.6541\n",
      "Epoch 01058 |  Loss 0.6536\n",
      "Epoch 01059 |  Loss 0.6540\n",
      "Epoch 01060 |  Loss 0.6540\n",
      "Epoch 01061 |  Loss 0.6546\n",
      "Epoch 01062 |  Loss 0.6542\n",
      "Epoch 01063 |  Loss 0.6539\n",
      "Epoch 01064 |  Loss 0.6540\n",
      "Epoch 01065 |  Loss 0.6544\n",
      "Epoch 01066 |  Loss 0.6540\n",
      "Epoch 01067 |  Loss 0.6535\n",
      "Epoch 01068 |  Loss 0.6541\n",
      "Epoch 01069 |  Loss 0.6539\n",
      "Epoch 01070 |  Loss 0.6538\n",
      "Epoch 01071 |  Loss 0.6544\n",
      "Epoch 01072 |  Loss 0.6541\n",
      "Epoch 01073 |  Loss 0.6537\n",
      "Epoch 01074 |  Loss 0.6540\n",
      "Epoch 01075 |  Loss 0.6539\n",
      "Epoch 01076 |  Loss 0.6537\n",
      "Epoch 01077 |  Loss 0.6534\n",
      "Epoch 01078 |  Loss 0.6534\n",
      "Epoch 01079 |  Loss 0.6538\n",
      "Epoch 01080 |  Loss 0.6536\n",
      "Epoch 01081 |  Loss 0.6538\n",
      "Epoch 01082 |  Loss 0.6536\n",
      "Epoch 01083 |  Loss 0.6539\n",
      "Epoch 01084 |  Loss 0.6539\n",
      "Epoch 01085 |  Loss 0.6533\n",
      "Epoch 01086 |  Loss 0.6539\n",
      "Epoch 01087 |  Loss 0.6533\n",
      "Epoch 01088 |  Loss 0.6541\n",
      "Epoch 01089 |  Loss 0.6535\n",
      "Epoch 01090 |  Loss 0.6543\n",
      "Epoch 01091 |  Loss 0.6536\n",
      "Epoch 01092 |  Loss 0.6537\n",
      "Epoch 01093 |  Loss 0.6533\n",
      "Epoch 01094 |  Loss 0.6538\n",
      "Epoch 01095 |  Loss 0.6534\n",
      "Epoch 01096 |  Loss 0.6539\n",
      "Epoch 01097 |  Loss 0.6539\n",
      "Epoch 01098 |  Loss 0.6538\n",
      "Epoch 01099 |  Loss 0.6538\n",
      "Epoch 01100 |  Loss 0.6533\n",
      "Epoch 01101 |  Loss 0.6536\n",
      "Epoch 01102 |  Loss 0.6532\n",
      "Epoch 01103 |  Loss 0.6532\n",
      "Epoch 01104 |  Loss 0.6533\n",
      "Epoch 01105 |  Loss 0.6536\n",
      "Epoch 01106 |  Loss 0.6535\n",
      "Epoch 01107 |  Loss 0.6537\n",
      "Epoch 01108 |  Loss 0.6533\n",
      "Epoch 01109 |  Loss 0.6535\n",
      "Epoch 01110 |  Loss 0.6533\n",
      "Epoch 01111 |  Loss 0.6534\n",
      "Epoch 01112 |  Loss 0.6545\n",
      "Epoch 01113 |  Loss 0.6537\n",
      "Epoch 01114 |  Loss 0.6536\n",
      "Epoch 01115 |  Loss 0.6534\n",
      "Epoch 01116 |  Loss 0.6532\n",
      "Epoch 01117 |  Loss 0.6532\n",
      "Epoch 01118 |  Loss 0.6533\n",
      "Epoch 01119 |  Loss 0.6534\n",
      "Epoch 01120 |  Loss 0.6532\n",
      "Epoch 01121 |  Loss 0.6536\n",
      "Epoch 01122 |  Loss 0.6534\n",
      "Epoch 01123 |  Loss 0.6532\n",
      "Epoch 01124 |  Loss 0.6535\n",
      "Epoch 01125 |  Loss 0.6534\n",
      "Epoch 01126 |  Loss 0.6529\n",
      "Epoch 01127 |  Loss 0.6535\n",
      "Epoch 01128 |  Loss 0.6529\n",
      "Epoch 01129 |  Loss 0.6528\n",
      "Epoch 01130 |  Loss 0.6537\n",
      "Epoch 01131 |  Loss 0.6532\n",
      "Epoch 01132 |  Loss 0.6529\n",
      "Epoch 01133 |  Loss 0.6532\n",
      "Epoch 01134 |  Loss 0.6536\n",
      "Epoch 01135 |  Loss 0.6534\n",
      "Epoch 01136 |  Loss 0.6535\n",
      "Epoch 01137 |  Loss 0.6532\n",
      "Epoch 01138 |  Loss 0.6533\n",
      "Epoch 01139 |  Loss 0.6532\n",
      "Epoch 01140 |  Loss 0.6535\n",
      "Epoch 01141 |  Loss 0.6529\n",
      "Epoch 01142 |  Loss 0.6527\n",
      "Epoch 01143 |  Loss 0.6532\n",
      "Epoch 01144 |  Loss 0.6530\n",
      "Epoch 01145 |  Loss 0.6530\n",
      "Epoch 01146 |  Loss 0.6528\n",
      "Epoch 01147 |  Loss 0.6529\n",
      "Epoch 01148 |  Loss 0.6532\n",
      "Epoch 01149 |  Loss 0.6530\n",
      "Epoch 01150 |  Loss 0.6528\n",
      "Epoch 01151 |  Loss 0.6529\n",
      "Epoch 01152 |  Loss 0.6532\n",
      "Epoch 01153 |  Loss 0.6525\n",
      "Epoch 01154 |  Loss 0.6532\n",
      "Epoch 01155 |  Loss 0.6531\n",
      "Epoch 01156 |  Loss 0.6532\n",
      "Epoch 01157 |  Loss 0.6526\n",
      "Epoch 01158 |  Loss 0.6531\n",
      "Epoch 01159 |  Loss 0.6530\n",
      "Epoch 01160 |  Loss 0.6529\n",
      "Epoch 01161 |  Loss 0.6530\n",
      "Epoch 01162 |  Loss 0.6528\n",
      "Epoch 01163 |  Loss 0.6524\n",
      "Epoch 01164 |  Loss 0.6525\n",
      "Epoch 01165 |  Loss 0.6529\n",
      "Epoch 01166 |  Loss 0.6525\n",
      "Epoch 01167 |  Loss 0.6531\n",
      "Epoch 01168 |  Loss 0.6528\n",
      "Epoch 01169 |  Loss 0.6526\n",
      "Epoch 01170 |  Loss 0.6530\n",
      "Epoch 01171 |  Loss 0.6525\n",
      "Epoch 01172 |  Loss 0.6526\n",
      "Epoch 01173 |  Loss 0.6528\n",
      "Epoch 01174 |  Loss 0.6534\n",
      "Epoch 01175 |  Loss 0.6527\n",
      "Epoch 01176 |  Loss 0.6525\n",
      "Epoch 01177 |  Loss 0.6528\n",
      "Epoch 01178 |  Loss 0.6530\n",
      "Epoch 01179 |  Loss 0.6523\n",
      "Epoch 01180 |  Loss 0.6527\n",
      "Epoch 01181 |  Loss 0.6529\n",
      "Epoch 01182 |  Loss 0.6531\n",
      "Epoch 01183 |  Loss 0.6529\n",
      "Epoch 01184 |  Loss 0.6527\n",
      "Epoch 01185 |  Loss 0.6529\n",
      "Epoch 01186 |  Loss 0.6526\n",
      "Epoch 01187 |  Loss 0.6530\n",
      "Epoch 01188 |  Loss 0.6524\n",
      "Epoch 01189 |  Loss 0.6527\n",
      "Epoch 01190 |  Loss 0.6529\n",
      "Epoch 01191 |  Loss 0.6526\n",
      "Epoch 01192 |  Loss 0.6532\n",
      "Epoch 01193 |  Loss 0.6528\n",
      "Epoch 01194 |  Loss 0.6528\n",
      "Epoch 01195 |  Loss 0.6525\n",
      "Epoch 01196 |  Loss 0.6527\n",
      "Epoch 01197 |  Loss 0.6524\n",
      "Epoch 01198 |  Loss 0.6525\n",
      "Epoch 01199 |  Loss 0.6522\n",
      "Epoch 01200 |  Loss 0.6523\n",
      "Epoch 01201 |  Loss 0.6524\n",
      "Epoch 01202 |  Loss 0.6523\n",
      "Epoch 01203 |  Loss 0.6526\n",
      "Epoch 01204 |  Loss 0.6527\n",
      "Epoch 01205 |  Loss 0.6525\n",
      "Epoch 01206 |  Loss 0.6524\n",
      "Epoch 01207 |  Loss 0.6523\n",
      "Epoch 01208 |  Loss 0.6527\n",
      "Epoch 01209 |  Loss 0.6522\n",
      "Epoch 01210 |  Loss 0.6525\n",
      "Epoch 01211 |  Loss 0.6526\n",
      "Epoch 01212 |  Loss 0.6527\n",
      "Epoch 01213 |  Loss 0.6524\n",
      "Epoch 01214 |  Loss 0.6527\n",
      "Epoch 01215 |  Loss 0.6527\n",
      "Epoch 01216 |  Loss 0.6522\n",
      "Epoch 01217 |  Loss 0.6523\n",
      "Epoch 01218 |  Loss 0.6525\n",
      "Epoch 01219 |  Loss 0.6522\n",
      "Epoch 01220 |  Loss 0.6525\n",
      "Epoch 01221 |  Loss 0.6525\n",
      "Epoch 01222 |  Loss 0.6530\n",
      "Epoch 01223 |  Loss 0.6523\n",
      "Epoch 01224 |  Loss 0.6521\n",
      "Epoch 01225 |  Loss 0.6525\n",
      "Epoch 01226 |  Loss 0.6520\n",
      "Epoch 01227 |  Loss 0.6520\n",
      "Epoch 01228 |  Loss 0.6520\n",
      "Epoch 01229 |  Loss 0.6525\n",
      "Epoch 01230 |  Loss 0.6524\n",
      "Epoch 01231 |  Loss 0.6523\n",
      "Epoch 01232 |  Loss 0.6521\n",
      "Epoch 01233 |  Loss 0.6523\n",
      "Epoch 01234 |  Loss 0.6521\n",
      "Epoch 01235 |  Loss 0.6521\n",
      "Epoch 01236 |  Loss 0.6525\n",
      "Epoch 01237 |  Loss 0.6523\n",
      "Epoch 01238 |  Loss 0.6523\n",
      "Epoch 01239 |  Loss 0.6522\n",
      "Epoch 01240 |  Loss 0.6523\n",
      "Epoch 01241 |  Loss 0.6524\n",
      "Epoch 01242 |  Loss 0.6520\n",
      "Epoch 01243 |  Loss 0.6520\n",
      "Epoch 01244 |  Loss 0.6524\n",
      "Epoch 01245 |  Loss 0.6516\n",
      "Epoch 01246 |  Loss 0.6525\n",
      "Epoch 01247 |  Loss 0.6521\n",
      "Epoch 01248 |  Loss 0.6520\n",
      "Epoch 01249 |  Loss 0.6522\n",
      "Epoch 01250 |  Loss 0.6521\n",
      "Epoch 01251 |  Loss 0.6524\n",
      "Epoch 01252 |  Loss 0.6518\n",
      "Epoch 01253 |  Loss 0.6517\n",
      "Epoch 01254 |  Loss 0.6521\n",
      "Epoch 01255 |  Loss 0.6518\n",
      "Epoch 01256 |  Loss 0.6516\n",
      "Epoch 01257 |  Loss 0.6518\n",
      "Epoch 01258 |  Loss 0.6515\n",
      "Epoch 01259 |  Loss 0.6518\n",
      "Epoch 01260 |  Loss 0.6522\n",
      "Epoch 01261 |  Loss 0.6518\n",
      "Epoch 01262 |  Loss 0.6519\n",
      "Epoch 01263 |  Loss 0.6523\n",
      "Epoch 01264 |  Loss 0.6519\n",
      "Epoch 01265 |  Loss 0.6518\n",
      "Epoch 01266 |  Loss 0.6520\n",
      "Epoch 01267 |  Loss 0.6518\n",
      "Epoch 01268 |  Loss 0.6516\n",
      "Epoch 01269 |  Loss 0.6518\n",
      "Epoch 01270 |  Loss 0.6523\n",
      "Epoch 01271 |  Loss 0.6517\n",
      "Epoch 01272 |  Loss 0.6516\n",
      "Epoch 01273 |  Loss 0.6517\n",
      "Epoch 01274 |  Loss 0.6522\n",
      "Epoch 01275 |  Loss 0.6520\n",
      "Epoch 01276 |  Loss 0.6523\n",
      "Epoch 01277 |  Loss 0.6521\n",
      "Epoch 01278 |  Loss 0.6521\n",
      "Epoch 01279 |  Loss 0.6518\n",
      "Epoch 01280 |  Loss 0.6517\n",
      "Epoch 01281 |  Loss 0.6519\n",
      "Epoch 01282 |  Loss 0.6520\n",
      "Epoch 01283 |  Loss 0.6517\n",
      "Epoch 01284 |  Loss 0.6520\n",
      "Epoch 01285 |  Loss 0.6515\n",
      "Epoch 01286 |  Loss 0.6524\n",
      "Epoch 01287 |  Loss 0.6513\n",
      "Epoch 01288 |  Loss 0.6523\n",
      "Epoch 01289 |  Loss 0.6518\n",
      "Epoch 01290 |  Loss 0.6515\n",
      "Epoch 01291 |  Loss 0.6520\n",
      "Epoch 01292 |  Loss 0.6518\n",
      "Epoch 01293 |  Loss 0.6517\n",
      "Epoch 01294 |  Loss 0.6518\n",
      "Epoch 01295 |  Loss 0.6518\n",
      "Epoch 01296 |  Loss 0.6514\n",
      "Epoch 01297 |  Loss 0.6512\n",
      "Epoch 01298 |  Loss 0.6518\n",
      "Epoch 01299 |  Loss 0.6518\n",
      "Epoch 01300 |  Loss 0.6517\n",
      "Epoch 01301 |  Loss 0.6518\n",
      "Epoch 01302 |  Loss 0.6513\n",
      "Epoch 01303 |  Loss 0.6514\n",
      "Epoch 01304 |  Loss 0.6514\n",
      "Epoch 01305 |  Loss 0.6518\n",
      "Epoch 01306 |  Loss 0.6520\n",
      "Epoch 01307 |  Loss 0.6514\n",
      "Epoch 01308 |  Loss 0.6513\n",
      "Epoch 01309 |  Loss 0.6515\n",
      "Epoch 01310 |  Loss 0.6517\n",
      "Epoch 01311 |  Loss 0.6518\n",
      "Epoch 01312 |  Loss 0.6515\n",
      "Epoch 01313 |  Loss 0.6517\n",
      "Epoch 01314 |  Loss 0.6518\n",
      "Epoch 01315 |  Loss 0.6514\n",
      "Epoch 01316 |  Loss 0.6515\n",
      "Epoch 01317 |  Loss 0.6513\n",
      "Epoch 01318 |  Loss 0.6521\n",
      "Epoch 01319 |  Loss 0.6516\n",
      "Epoch 01320 |  Loss 0.6518\n",
      "Epoch 01321 |  Loss 0.6512\n",
      "Epoch 01322 |  Loss 0.6516\n",
      "Epoch 01323 |  Loss 0.6517\n",
      "Epoch 01324 |  Loss 0.6514\n",
      "Epoch 01325 |  Loss 0.6515\n",
      "Epoch 01326 |  Loss 0.6510\n",
      "Epoch 01327 |  Loss 0.6513\n",
      "Epoch 01328 |  Loss 0.6516\n",
      "Epoch 01329 |  Loss 0.6507\n",
      "Epoch 01330 |  Loss 0.6509\n",
      "Epoch 01331 |  Loss 0.6516\n",
      "Epoch 01332 |  Loss 0.6510\n",
      "Epoch 01333 |  Loss 0.6515\n",
      "Epoch 01334 |  Loss 0.6516\n",
      "Epoch 01335 |  Loss 0.6515\n",
      "Epoch 01336 |  Loss 0.6513\n",
      "Epoch 01337 |  Loss 0.6516\n",
      "Epoch 01338 |  Loss 0.6512\n",
      "Epoch 01339 |  Loss 0.6518\n",
      "Epoch 01340 |  Loss 0.6514\n",
      "Epoch 01341 |  Loss 0.6512\n",
      "Epoch 01342 |  Loss 0.6516\n",
      "Epoch 01343 |  Loss 0.6509\n",
      "Epoch 01344 |  Loss 0.6512\n",
      "Epoch 01345 |  Loss 0.6513\n",
      "Epoch 01346 |  Loss 0.6513\n",
      "Epoch 01347 |  Loss 0.6516\n",
      "Epoch 01348 |  Loss 0.6512\n",
      "Epoch 01349 |  Loss 0.6511\n",
      "Epoch 01350 |  Loss 0.6514\n",
      "Epoch 01351 |  Loss 0.6510\n",
      "Epoch 01352 |  Loss 0.6509\n",
      "Epoch 01353 |  Loss 0.6513\n",
      "Epoch 01354 |  Loss 0.6512\n",
      "Epoch 01355 |  Loss 0.6510\n",
      "Epoch 01356 |  Loss 0.6511\n",
      "Epoch 01357 |  Loss 0.6514\n",
      "Epoch 01358 |  Loss 0.6512\n",
      "Epoch 01359 |  Loss 0.6512\n",
      "Epoch 01360 |  Loss 0.6509\n",
      "Epoch 01361 |  Loss 0.6508\n",
      "Epoch 01362 |  Loss 0.6509\n",
      "Epoch 01363 |  Loss 0.6509\n",
      "Epoch 01364 |  Loss 0.6504\n",
      "Epoch 01365 |  Loss 0.6509\n",
      "Epoch 01366 |  Loss 0.6514\n",
      "Epoch 01367 |  Loss 0.6514\n",
      "Epoch 01368 |  Loss 0.6510\n",
      "Epoch 01369 |  Loss 0.6510\n",
      "Epoch 01370 |  Loss 0.6509\n",
      "Epoch 01371 |  Loss 0.6509\n",
      "Epoch 01372 |  Loss 0.6511\n",
      "Epoch 01373 |  Loss 0.6514\n",
      "Epoch 01374 |  Loss 0.6513\n",
      "Epoch 01375 |  Loss 0.6509\n",
      "Epoch 01376 |  Loss 0.6511\n",
      "Epoch 01377 |  Loss 0.6504\n",
      "Epoch 01378 |  Loss 0.6505\n",
      "Epoch 01379 |  Loss 0.6513\n",
      "Epoch 01380 |  Loss 0.6510\n",
      "Epoch 01381 |  Loss 0.6511\n",
      "Epoch 01382 |  Loss 0.6515\n",
      "Epoch 01383 |  Loss 0.6516\n",
      "Epoch 01384 |  Loss 0.6507\n",
      "Epoch 01385 |  Loss 0.6509\n",
      "Epoch 01386 |  Loss 0.6506\n",
      "Epoch 01387 |  Loss 0.6512\n",
      "Epoch 01388 |  Loss 0.6515\n",
      "Epoch 01389 |  Loss 0.6510\n",
      "Epoch 01390 |  Loss 0.6509\n",
      "Epoch 01391 |  Loss 0.6506\n",
      "Epoch 01392 |  Loss 0.6512\n",
      "Epoch 01393 |  Loss 0.6511\n",
      "Epoch 01394 |  Loss 0.6504\n",
      "Epoch 01395 |  Loss 0.6506\n",
      "Epoch 01396 |  Loss 0.6507\n",
      "Epoch 01397 |  Loss 0.6507\n",
      "Epoch 01398 |  Loss 0.6506\n",
      "Epoch 01399 |  Loss 0.6508\n",
      "Epoch 01400 |  Loss 0.6506\n",
      "Epoch 01401 |  Loss 0.6507\n",
      "Epoch 01402 |  Loss 0.6506\n",
      "Epoch 01403 |  Loss 0.6507\n",
      "Epoch 01404 |  Loss 0.6507\n",
      "Epoch 01405 |  Loss 0.6508\n",
      "Epoch 01406 |  Loss 0.6514\n",
      "Epoch 01407 |  Loss 0.6511\n",
      "Epoch 01408 |  Loss 0.6510\n",
      "Epoch 01409 |  Loss 0.6511\n",
      "Epoch 01410 |  Loss 0.6505\n",
      "Epoch 01411 |  Loss 0.6506\n",
      "Epoch 01412 |  Loss 0.6508\n",
      "Epoch 01413 |  Loss 0.6507\n",
      "Epoch 01414 |  Loss 0.6505\n",
      "Epoch 01415 |  Loss 0.6503\n",
      "Epoch 01416 |  Loss 0.6503\n",
      "Epoch 01417 |  Loss 0.6506\n",
      "Epoch 01418 |  Loss 0.6509\n",
      "Epoch 01419 |  Loss 0.6508\n",
      "Epoch 01420 |  Loss 0.6506\n",
      "Epoch 01421 |  Loss 0.6504\n",
      "Epoch 01422 |  Loss 0.6502\n",
      "Epoch 01423 |  Loss 0.6505\n",
      "Epoch 01424 |  Loss 0.6507\n",
      "Epoch 01425 |  Loss 0.6504\n",
      "Epoch 01426 |  Loss 0.6502\n",
      "Epoch 01427 |  Loss 0.6505\n",
      "Epoch 01428 |  Loss 0.6502\n",
      "Epoch 01429 |  Loss 0.6507\n",
      "Epoch 01430 |  Loss 0.6506\n",
      "Epoch 01431 |  Loss 0.6500\n",
      "Epoch 01432 |  Loss 0.6500\n",
      "Epoch 01433 |  Loss 0.6504\n",
      "Epoch 01434 |  Loss 0.6508\n",
      "Epoch 01435 |  Loss 0.6508\n",
      "Epoch 01436 |  Loss 0.6503\n",
      "Epoch 01437 |  Loss 0.6503\n",
      "Epoch 01438 |  Loss 0.6505\n",
      "Epoch 01439 |  Loss 0.6503\n",
      "Epoch 01440 |  Loss 0.6506\n",
      "Epoch 01441 |  Loss 0.6504\n",
      "Epoch 01442 |  Loss 0.6502\n",
      "Epoch 01443 |  Loss 0.6507\n",
      "Epoch 01444 |  Loss 0.6504\n",
      "Epoch 01445 |  Loss 0.6505\n",
      "Epoch 01446 |  Loss 0.6501\n",
      "Epoch 01447 |  Loss 0.6503\n",
      "Epoch 01448 |  Loss 0.6501\n",
      "Epoch 01449 |  Loss 0.6502\n",
      "Epoch 01450 |  Loss 0.6502\n",
      "Epoch 01451 |  Loss 0.6501\n",
      "Epoch 01452 |  Loss 0.6504\n",
      "Epoch 01453 |  Loss 0.6496\n",
      "Epoch 01454 |  Loss 0.6504\n",
      "Epoch 01455 |  Loss 0.6498\n",
      "Epoch 01456 |  Loss 0.6504\n",
      "Epoch 01457 |  Loss 0.6500\n",
      "Epoch 01458 |  Loss 0.6504\n",
      "Epoch 01459 |  Loss 0.6505\n",
      "Epoch 01460 |  Loss 0.6502\n",
      "Epoch 01461 |  Loss 0.6500\n",
      "Epoch 01462 |  Loss 0.6502\n",
      "Epoch 01463 |  Loss 0.6504\n",
      "Epoch 01464 |  Loss 0.6505\n",
      "Epoch 01465 |  Loss 0.6504\n",
      "Epoch 01466 |  Loss 0.6499\n",
      "Epoch 01467 |  Loss 0.6508\n",
      "Epoch 01468 |  Loss 0.6502\n",
      "Epoch 01469 |  Loss 0.6503\n",
      "Epoch 01470 |  Loss 0.6505\n",
      "Epoch 01471 |  Loss 0.6500\n",
      "Epoch 01472 |  Loss 0.6499\n",
      "Epoch 01473 |  Loss 0.6506\n",
      "Epoch 01474 |  Loss 0.6502\n",
      "Epoch 01475 |  Loss 0.6503\n",
      "Epoch 01476 |  Loss 0.6504\n",
      "Epoch 01477 |  Loss 0.6501\n",
      "Epoch 01478 |  Loss 0.6500\n",
      "Epoch 01479 |  Loss 0.6508\n",
      "Epoch 01480 |  Loss 0.6504\n",
      "Epoch 01481 |  Loss 0.6504\n",
      "Epoch 01482 |  Loss 0.6497\n",
      "Epoch 01483 |  Loss 0.6503\n",
      "Epoch 01484 |  Loss 0.6504\n",
      "Epoch 01485 |  Loss 0.6500\n",
      "Epoch 01486 |  Loss 0.6504\n",
      "Epoch 01487 |  Loss 0.6499\n",
      "Epoch 01488 |  Loss 0.6500\n",
      "Epoch 01489 |  Loss 0.6496\n",
      "Epoch 01490 |  Loss 0.6500\n",
      "Epoch 01491 |  Loss 0.6501\n",
      "Epoch 01492 |  Loss 0.6499\n",
      "Epoch 01493 |  Loss 0.6504\n",
      "Epoch 01494 |  Loss 0.6498\n",
      "Epoch 01495 |  Loss 0.6496\n",
      "Epoch 01496 |  Loss 0.6505\n",
      "Epoch 01497 |  Loss 0.6501\n",
      "Epoch 01498 |  Loss 0.6500\n",
      "Epoch 01499 |  Loss 0.6502\n",
      "Epoch 01500 |  Loss 0.6503\n",
      "Epoch 01501 |  Loss 0.6498\n",
      "Epoch 01502 |  Loss 0.6501\n",
      "Epoch 01503 |  Loss 0.6500\n",
      "Epoch 01504 |  Loss 0.6502\n",
      "Epoch 01505 |  Loss 0.6501\n",
      "Epoch 01506 |  Loss 0.6496\n",
      "Epoch 01507 |  Loss 0.6497\n",
      "Epoch 01508 |  Loss 0.6499\n",
      "Epoch 01509 |  Loss 0.6505\n",
      "Epoch 01510 |  Loss 0.6502\n",
      "Epoch 01511 |  Loss 0.6498\n",
      "Epoch 01512 |  Loss 0.6499\n",
      "Epoch 01513 |  Loss 0.6501\n",
      "Epoch 01514 |  Loss 0.6497\n",
      "Epoch 01515 |  Loss 0.6497\n",
      "Epoch 01516 |  Loss 0.6497\n",
      "Epoch 01517 |  Loss 0.6501\n",
      "Epoch 01518 |  Loss 0.6500\n",
      "Epoch 01519 |  Loss 0.6501\n",
      "Epoch 01520 |  Loss 0.6501\n",
      "Epoch 01521 |  Loss 0.6498\n",
      "Epoch 01522 |  Loss 0.6499\n",
      "Epoch 01523 |  Loss 0.6498\n",
      "Epoch 01524 |  Loss 0.6500\n",
      "Epoch 01525 |  Loss 0.6496\n",
      "Epoch 01526 |  Loss 0.6495\n",
      "Epoch 01527 |  Loss 0.6495\n",
      "Epoch 01528 |  Loss 0.6504\n",
      "Epoch 01529 |  Loss 0.6501\n",
      "Epoch 01530 |  Loss 0.6500\n",
      "Epoch 01531 |  Loss 0.6502\n",
      "Epoch 01532 |  Loss 0.6499\n",
      "Epoch 01533 |  Loss 0.6501\n",
      "Epoch 01534 |  Loss 0.6496\n",
      "Epoch 01535 |  Loss 0.6499\n",
      "Epoch 01536 |  Loss 0.6503\n",
      "Epoch 01537 |  Loss 0.6495\n",
      "Epoch 01538 |  Loss 0.6499\n",
      "Epoch 01539 |  Loss 0.6497\n",
      "Epoch 01540 |  Loss 0.6500\n",
      "Epoch 01541 |  Loss 0.6500\n",
      "Epoch 01542 |  Loss 0.6502\n",
      "Epoch 01543 |  Loss 0.6498\n",
      "Epoch 01544 |  Loss 0.6499\n",
      "Epoch 01545 |  Loss 0.6499\n",
      "Epoch 01546 |  Loss 0.6498\n",
      "Epoch 01547 |  Loss 0.6499\n",
      "Epoch 01548 |  Loss 0.6495\n",
      "Epoch 01549 |  Loss 0.6496\n",
      "Epoch 01550 |  Loss 0.6495\n",
      "Epoch 01551 |  Loss 0.6496\n",
      "Epoch 01552 |  Loss 0.6494\n",
      "Epoch 01553 |  Loss 0.6497\n",
      "Epoch 01554 |  Loss 0.6500\n",
      "Epoch 01555 |  Loss 0.6497\n",
      "Epoch 01556 |  Loss 0.6492\n",
      "Epoch 01557 |  Loss 0.6495\n",
      "Epoch 01558 |  Loss 0.6495\n",
      "Epoch 01559 |  Loss 0.6495\n",
      "Epoch 01560 |  Loss 0.6496\n",
      "Epoch 01561 |  Loss 0.6497\n",
      "Epoch 01562 |  Loss 0.6494\n",
      "Epoch 01563 |  Loss 0.6492\n",
      "Epoch 01564 |  Loss 0.6498\n",
      "Epoch 01565 |  Loss 0.6496\n",
      "Epoch 01566 |  Loss 0.6494\n",
      "Epoch 01567 |  Loss 0.6499\n",
      "Epoch 01568 |  Loss 0.6499\n",
      "Epoch 01569 |  Loss 0.6494\n",
      "Epoch 01570 |  Loss 0.6493\n",
      "Epoch 01571 |  Loss 0.6496\n",
      "Epoch 01572 |  Loss 0.6495\n",
      "Epoch 01573 |  Loss 0.6493\n",
      "Epoch 01574 |  Loss 0.6496\n",
      "Epoch 01575 |  Loss 0.6495\n",
      "Epoch 01576 |  Loss 0.6492\n",
      "Epoch 01577 |  Loss 0.6503\n",
      "Epoch 01578 |  Loss 0.6494\n",
      "Epoch 01579 |  Loss 0.6494\n",
      "Epoch 01580 |  Loss 0.6494\n",
      "Epoch 01581 |  Loss 0.6493\n",
      "Epoch 01582 |  Loss 0.6490\n",
      "Epoch 01583 |  Loss 0.6492\n",
      "Epoch 01584 |  Loss 0.6500\n",
      "Epoch 01585 |  Loss 0.6499\n",
      "Epoch 01586 |  Loss 0.6495\n",
      "Epoch 01587 |  Loss 0.6496\n",
      "Epoch 01588 |  Loss 0.6498\n",
      "Epoch 01589 |  Loss 0.6493\n",
      "Epoch 01590 |  Loss 0.6494\n",
      "Epoch 01591 |  Loss 0.6496\n",
      "Epoch 01592 |  Loss 0.6495\n",
      "Epoch 01593 |  Loss 0.6491\n",
      "Epoch 01594 |  Loss 0.6490\n",
      "Epoch 01595 |  Loss 0.6499\n",
      "Epoch 01596 |  Loss 0.6498\n",
      "Epoch 01597 |  Loss 0.6492\n",
      "Epoch 01598 |  Loss 0.6495\n",
      "Epoch 01599 |  Loss 0.6497\n",
      "Epoch 01600 |  Loss 0.6495\n",
      "Epoch 01601 |  Loss 0.6495\n",
      "Epoch 01602 |  Loss 0.6490\n",
      "Epoch 01603 |  Loss 0.6497\n",
      "Epoch 01604 |  Loss 0.6496\n",
      "Epoch 01605 |  Loss 0.6494\n",
      "Epoch 01606 |  Loss 0.6493\n",
      "Epoch 01607 |  Loss 0.6492\n",
      "Epoch 01608 |  Loss 0.6492\n",
      "Epoch 01609 |  Loss 0.6490\n",
      "Epoch 01610 |  Loss 0.6495\n",
      "Epoch 01611 |  Loss 0.6492\n",
      "Epoch 01612 |  Loss 0.6491\n",
      "Epoch 01613 |  Loss 0.6502\n",
      "Epoch 01614 |  Loss 0.6493\n",
      "Epoch 01615 |  Loss 0.6488\n",
      "Epoch 01616 |  Loss 0.6494\n",
      "Epoch 01617 |  Loss 0.6487\n",
      "Epoch 01618 |  Loss 0.6492\n",
      "Epoch 01619 |  Loss 0.6495\n",
      "Epoch 01620 |  Loss 0.6493\n",
      "Epoch 01621 |  Loss 0.6495\n",
      "Epoch 01622 |  Loss 0.6492\n",
      "Epoch 01623 |  Loss 0.6492\n",
      "Epoch 01624 |  Loss 0.6490\n",
      "Epoch 01625 |  Loss 0.6491\n",
      "Epoch 01626 |  Loss 0.6492\n",
      "Epoch 01627 |  Loss 0.6489\n",
      "Epoch 01628 |  Loss 0.6489\n",
      "Epoch 01629 |  Loss 0.6495\n",
      "Epoch 01630 |  Loss 0.6493\n",
      "Epoch 01631 |  Loss 0.6491\n",
      "Epoch 01632 |  Loss 0.6493\n",
      "Epoch 01633 |  Loss 0.6492\n",
      "Epoch 01634 |  Loss 0.6496\n",
      "Epoch 01635 |  Loss 0.6494\n",
      "Epoch 01636 |  Loss 0.6489\n",
      "Epoch 01637 |  Loss 0.6494\n",
      "Epoch 01638 |  Loss 0.6492\n",
      "Epoch 01639 |  Loss 0.6483\n",
      "Epoch 01640 |  Loss 0.6494\n",
      "Epoch 01641 |  Loss 0.6492\n",
      "Epoch 01642 |  Loss 0.6487\n",
      "Epoch 01643 |  Loss 0.6491\n",
      "Epoch 01644 |  Loss 0.6494\n",
      "Epoch 01645 |  Loss 0.6492\n",
      "Epoch 01646 |  Loss 0.6491\n",
      "Epoch 01647 |  Loss 0.6492\n",
      "Epoch 01648 |  Loss 0.6490\n",
      "Epoch 01649 |  Loss 0.6489\n",
      "Epoch 01650 |  Loss 0.6491\n",
      "Epoch 01651 |  Loss 0.6488\n",
      "Epoch 01652 |  Loss 0.6489\n",
      "Epoch 01653 |  Loss 0.6487\n",
      "Epoch 01654 |  Loss 0.6490\n",
      "Epoch 01655 |  Loss 0.6486\n",
      "Epoch 01656 |  Loss 0.6489\n",
      "Epoch 01657 |  Loss 0.6487\n",
      "Epoch 01658 |  Loss 0.6491\n",
      "Epoch 01659 |  Loss 0.6488\n",
      "Epoch 01660 |  Loss 0.6488\n",
      "Epoch 01661 |  Loss 0.6491\n",
      "Epoch 01662 |  Loss 0.6487\n",
      "Epoch 01663 |  Loss 0.6489\n",
      "Epoch 01664 |  Loss 0.6487\n",
      "Epoch 01665 |  Loss 0.6489\n",
      "Epoch 01666 |  Loss 0.6486\n",
      "Epoch 01667 |  Loss 0.6488\n",
      "Epoch 01668 |  Loss 0.6489\n",
      "Epoch 01669 |  Loss 0.6492\n",
      "Epoch 01670 |  Loss 0.6487\n",
      "Epoch 01671 |  Loss 0.6491\n",
      "Epoch 01672 |  Loss 0.6488\n",
      "Epoch 01673 |  Loss 0.6488\n",
      "Epoch 01674 |  Loss 0.6487\n",
      "Epoch 01675 |  Loss 0.6489\n",
      "Epoch 01676 |  Loss 0.6491\n",
      "Epoch 01677 |  Loss 0.6491\n",
      "Epoch 01678 |  Loss 0.6484\n",
      "Epoch 01679 |  Loss 0.6490\n",
      "Epoch 01680 |  Loss 0.6489\n",
      "Epoch 01681 |  Loss 0.6490\n",
      "Epoch 01682 |  Loss 0.6482\n",
      "Epoch 01683 |  Loss 0.6486\n",
      "Epoch 01684 |  Loss 0.6486\n",
      "Epoch 01685 |  Loss 0.6491\n",
      "Epoch 01686 |  Loss 0.6485\n",
      "Epoch 01687 |  Loss 0.6487\n",
      "Epoch 01688 |  Loss 0.6491\n",
      "Epoch 01689 |  Loss 0.6488\n",
      "Epoch 01690 |  Loss 0.6486\n",
      "Epoch 01691 |  Loss 0.6484\n",
      "Epoch 01692 |  Loss 0.6491\n",
      "Epoch 01693 |  Loss 0.6491\n",
      "Epoch 01694 |  Loss 0.6484\n",
      "Epoch 01695 |  Loss 0.6484\n",
      "Epoch 01696 |  Loss 0.6485\n",
      "Epoch 01697 |  Loss 0.6490\n",
      "Epoch 01698 |  Loss 0.6492\n",
      "Epoch 01699 |  Loss 0.6492\n",
      "Epoch 01700 |  Loss 0.6487\n",
      "Epoch 01701 |  Loss 0.6489\n",
      "Epoch 01702 |  Loss 0.6488\n",
      "Epoch 01703 |  Loss 0.6493\n",
      "Epoch 01704 |  Loss 0.6486\n",
      "Epoch 01705 |  Loss 0.6489\n",
      "Epoch 01706 |  Loss 0.6487\n",
      "Epoch 01707 |  Loss 0.6490\n",
      "Epoch 01708 |  Loss 0.6486\n",
      "Epoch 01709 |  Loss 0.6487\n",
      "Epoch 01710 |  Loss 0.6485\n",
      "Epoch 01711 |  Loss 0.6485\n",
      "Epoch 01712 |  Loss 0.6487\n",
      "Epoch 01713 |  Loss 0.6488\n",
      "Epoch 01714 |  Loss 0.6486\n",
      "Epoch 01715 |  Loss 0.6481\n",
      "Epoch 01716 |  Loss 0.6484\n",
      "Epoch 01717 |  Loss 0.6488\n",
      "Epoch 01718 |  Loss 0.6490\n",
      "Epoch 01719 |  Loss 0.6484\n",
      "Epoch 01720 |  Loss 0.6483\n",
      "Epoch 01721 |  Loss 0.6485\n",
      "Epoch 01722 |  Loss 0.6481\n",
      "Epoch 01723 |  Loss 0.6487\n",
      "Epoch 01724 |  Loss 0.6487\n",
      "Epoch 01725 |  Loss 0.6483\n",
      "Epoch 01726 |  Loss 0.6484\n",
      "Epoch 01727 |  Loss 0.6487\n",
      "Epoch 01728 |  Loss 0.6487\n",
      "Epoch 01729 |  Loss 0.6488\n",
      "Epoch 01730 |  Loss 0.6485\n",
      "Epoch 01731 |  Loss 0.6482\n",
      "Epoch 01732 |  Loss 0.6486\n",
      "Epoch 01733 |  Loss 0.6482\n",
      "Epoch 01734 |  Loss 0.6485\n",
      "Epoch 01735 |  Loss 0.6486\n",
      "Epoch 01736 |  Loss 0.6481\n",
      "Epoch 01737 |  Loss 0.6484\n",
      "Epoch 01738 |  Loss 0.6484\n",
      "Epoch 01739 |  Loss 0.6480\n",
      "Epoch 01740 |  Loss 0.6484\n",
      "Epoch 01741 |  Loss 0.6484\n",
      "Epoch 01742 |  Loss 0.6482\n",
      "Epoch 01743 |  Loss 0.6489\n",
      "Epoch 01744 |  Loss 0.6484\n",
      "Epoch 01745 |  Loss 0.6481\n",
      "Epoch 01746 |  Loss 0.6482\n",
      "Epoch 01747 |  Loss 0.6483\n",
      "Epoch 01748 |  Loss 0.6480\n",
      "Epoch 01749 |  Loss 0.6487\n",
      "Epoch 01750 |  Loss 0.6489\n",
      "Epoch 01751 |  Loss 0.6484\n",
      "Epoch 01752 |  Loss 0.6481\n",
      "Epoch 01753 |  Loss 0.6484\n",
      "Epoch 01754 |  Loss 0.6488\n",
      "Epoch 01755 |  Loss 0.6482\n",
      "Epoch 01756 |  Loss 0.6482\n",
      "Epoch 01757 |  Loss 0.6481\n",
      "Epoch 01758 |  Loss 0.6483\n",
      "Epoch 01759 |  Loss 0.6487\n",
      "Epoch 01760 |  Loss 0.6486\n",
      "Epoch 01761 |  Loss 0.6485\n",
      "Epoch 01762 |  Loss 0.6480\n",
      "Epoch 01763 |  Loss 0.6480\n",
      "Epoch 01764 |  Loss 0.6485\n",
      "Epoch 01765 |  Loss 0.6483\n",
      "Epoch 01766 |  Loss 0.6485\n",
      "Epoch 01767 |  Loss 0.6484\n",
      "Epoch 01768 |  Loss 0.6485\n",
      "Epoch 01769 |  Loss 0.6479\n",
      "Epoch 01770 |  Loss 0.6485\n",
      "Epoch 01771 |  Loss 0.6487\n",
      "Epoch 01772 |  Loss 0.6484\n",
      "Epoch 01773 |  Loss 0.6480\n",
      "Epoch 01774 |  Loss 0.6480\n",
      "Epoch 01775 |  Loss 0.6481\n",
      "Epoch 01776 |  Loss 0.6486\n",
      "Epoch 01777 |  Loss 0.6482\n",
      "Epoch 01778 |  Loss 0.6480\n",
      "Epoch 01779 |  Loss 0.6482\n",
      "Epoch 01780 |  Loss 0.6485\n",
      "Epoch 01781 |  Loss 0.6477\n",
      "Epoch 01782 |  Loss 0.6482\n",
      "Epoch 01783 |  Loss 0.6484\n",
      "Epoch 01784 |  Loss 0.6481\n",
      "Epoch 01785 |  Loss 0.6482\n",
      "Epoch 01786 |  Loss 0.6486\n",
      "Epoch 01787 |  Loss 0.6483\n",
      "Epoch 01788 |  Loss 0.6479\n",
      "Epoch 01789 |  Loss 0.6483\n",
      "Epoch 01790 |  Loss 0.6482\n",
      "Epoch 01791 |  Loss 0.6483\n",
      "Epoch 01792 |  Loss 0.6484\n",
      "Epoch 01793 |  Loss 0.6483\n",
      "Epoch 01794 |  Loss 0.6480\n",
      "Epoch 01795 |  Loss 0.6480\n",
      "Epoch 01796 |  Loss 0.6481\n",
      "Epoch 01797 |  Loss 0.6484\n",
      "Epoch 01798 |  Loss 0.6480\n",
      "Epoch 01799 |  Loss 0.6477\n",
      "Epoch 01800 |  Loss 0.6483\n",
      "Epoch 01801 |  Loss 0.6480\n",
      "Epoch 01802 |  Loss 0.6481\n",
      "Epoch 01803 |  Loss 0.6485\n",
      "Epoch 01804 |  Loss 0.6478\n",
      "Epoch 01805 |  Loss 0.6480\n",
      "Epoch 01806 |  Loss 0.6481\n",
      "Epoch 01807 |  Loss 0.6478\n",
      "Epoch 01808 |  Loss 0.6478\n",
      "Epoch 01809 |  Loss 0.6478\n",
      "Epoch 01810 |  Loss 0.6479\n",
      "Epoch 01811 |  Loss 0.6480\n",
      "Epoch 01812 |  Loss 0.6483\n",
      "Epoch 01813 |  Loss 0.6480\n",
      "Epoch 01814 |  Loss 0.6479\n",
      "Epoch 01815 |  Loss 0.6481\n",
      "Epoch 01816 |  Loss 0.6484\n",
      "Epoch 01817 |  Loss 0.6480\n",
      "Epoch 01818 |  Loss 0.6478\n",
      "Epoch 01819 |  Loss 0.6482\n",
      "Epoch 01820 |  Loss 0.6484\n",
      "Epoch 01821 |  Loss 0.6478\n",
      "Epoch 01822 |  Loss 0.6479\n",
      "Epoch 01823 |  Loss 0.6478\n",
      "Epoch 01824 |  Loss 0.6479\n",
      "Epoch 01825 |  Loss 0.6476\n",
      "Epoch 01826 |  Loss 0.6479\n",
      "Epoch 01827 |  Loss 0.6481\n",
      "Epoch 01828 |  Loss 0.6485\n",
      "Epoch 01829 |  Loss 0.6479\n",
      "Epoch 01830 |  Loss 0.6479\n",
      "Epoch 01831 |  Loss 0.6474\n",
      "Epoch 01832 |  Loss 0.6481\n",
      "Epoch 01833 |  Loss 0.6478\n",
      "Epoch 01834 |  Loss 0.6480\n",
      "Epoch 01835 |  Loss 0.6478\n",
      "Epoch 01836 |  Loss 0.6479\n",
      "Epoch 01837 |  Loss 0.6480\n",
      "Epoch 01838 |  Loss 0.6480\n",
      "Epoch 01839 |  Loss 0.6473\n",
      "Epoch 01840 |  Loss 0.6476\n",
      "Epoch 01841 |  Loss 0.6473\n",
      "Epoch 01842 |  Loss 0.6483\n",
      "Epoch 01843 |  Loss 0.6476\n",
      "Epoch 01844 |  Loss 0.6472\n",
      "Epoch 01845 |  Loss 0.6476\n",
      "Epoch 01846 |  Loss 0.6476\n",
      "Epoch 01847 |  Loss 0.6475\n",
      "Epoch 01848 |  Loss 0.6479\n",
      "Epoch 01849 |  Loss 0.6480\n",
      "Epoch 01850 |  Loss 0.6484\n",
      "Epoch 01851 |  Loss 0.6475\n",
      "Epoch 01852 |  Loss 0.6478\n",
      "Epoch 01853 |  Loss 0.6479\n",
      "Epoch 01854 |  Loss 0.6477\n",
      "Epoch 01855 |  Loss 0.6481\n",
      "Epoch 01856 |  Loss 0.6472\n",
      "Epoch 01857 |  Loss 0.6475\n",
      "Epoch 01858 |  Loss 0.6478\n",
      "Epoch 01859 |  Loss 0.6481\n",
      "Epoch 01860 |  Loss 0.6478\n",
      "Epoch 01861 |  Loss 0.6478\n",
      "Epoch 01862 |  Loss 0.6481\n",
      "Epoch 01863 |  Loss 0.6475\n",
      "Epoch 01864 |  Loss 0.6479\n",
      "Epoch 01865 |  Loss 0.6477\n",
      "Epoch 01866 |  Loss 0.6480\n",
      "Epoch 01867 |  Loss 0.6479\n",
      "Epoch 01868 |  Loss 0.6481\n",
      "Epoch 01869 |  Loss 0.6481\n",
      "Epoch 01870 |  Loss 0.6478\n",
      "Epoch 01871 |  Loss 0.6477\n",
      "Epoch 01872 |  Loss 0.6479\n",
      "Epoch 01873 |  Loss 0.6477\n",
      "Epoch 01874 |  Loss 0.6475\n",
      "Epoch 01875 |  Loss 0.6481\n",
      "Epoch 01876 |  Loss 0.6478\n",
      "Epoch 01877 |  Loss 0.6483\n",
      "Epoch 01878 |  Loss 0.6478\n",
      "Epoch 01879 |  Loss 0.6476\n",
      "Epoch 01880 |  Loss 0.6477\n",
      "Epoch 01881 |  Loss 0.6477\n",
      "Epoch 01882 |  Loss 0.6471\n",
      "Epoch 01883 |  Loss 0.6477\n",
      "Epoch 01884 |  Loss 0.6473\n",
      "Epoch 01885 |  Loss 0.6475\n",
      "Epoch 01886 |  Loss 0.6479\n",
      "Epoch 01887 |  Loss 0.6478\n",
      "Epoch 01888 |  Loss 0.6476\n",
      "Epoch 01889 |  Loss 0.6475\n",
      "Epoch 01890 |  Loss 0.6472\n",
      "Epoch 01891 |  Loss 0.6476\n",
      "Epoch 01892 |  Loss 0.6481\n",
      "Epoch 01893 |  Loss 0.6481\n",
      "Epoch 01894 |  Loss 0.6475\n",
      "Epoch 01895 |  Loss 0.6476\n",
      "Epoch 01896 |  Loss 0.6476\n",
      "Epoch 01897 |  Loss 0.6478\n",
      "Epoch 01898 |  Loss 0.6479\n",
      "Epoch 01899 |  Loss 0.6479\n",
      "Epoch 01900 |  Loss 0.6471\n",
      "Epoch 01901 |  Loss 0.6474\n",
      "Epoch 01902 |  Loss 0.6480\n",
      "Epoch 01903 |  Loss 0.6475\n",
      "Epoch 01904 |  Loss 0.6469\n",
      "Epoch 01905 |  Loss 0.6476\n",
      "Epoch 01906 |  Loss 0.6473\n",
      "Epoch 01907 |  Loss 0.6471\n",
      "Epoch 01908 |  Loss 0.6477\n",
      "Epoch 01909 |  Loss 0.6475\n",
      "Epoch 01910 |  Loss 0.6473\n",
      "Epoch 01911 |  Loss 0.6478\n",
      "Epoch 01912 |  Loss 0.6471\n",
      "Epoch 01913 |  Loss 0.6480\n",
      "Epoch 01914 |  Loss 0.6477\n",
      "Epoch 01915 |  Loss 0.6473\n",
      "Epoch 01916 |  Loss 0.6471\n",
      "Epoch 01917 |  Loss 0.6466\n",
      "Epoch 01918 |  Loss 0.6473\n",
      "Epoch 01919 |  Loss 0.6474\n",
      "Epoch 01920 |  Loss 0.6475\n",
      "Epoch 01921 |  Loss 0.6475\n",
      "Epoch 01922 |  Loss 0.6476\n",
      "Epoch 01923 |  Loss 0.6476\n",
      "Epoch 01924 |  Loss 0.6476\n",
      "Epoch 01925 |  Loss 0.6473\n",
      "Epoch 01926 |  Loss 0.6473\n",
      "Epoch 01927 |  Loss 0.6472\n",
      "Epoch 01928 |  Loss 0.6475\n",
      "Epoch 01929 |  Loss 0.6478\n",
      "Epoch 01930 |  Loss 0.6475\n",
      "Epoch 01931 |  Loss 0.6471\n",
      "Epoch 01932 |  Loss 0.6472\n",
      "Epoch 01933 |  Loss 0.6475\n",
      "Epoch 01934 |  Loss 0.6472\n",
      "Epoch 01935 |  Loss 0.6470\n",
      "Epoch 01936 |  Loss 0.6473\n",
      "Epoch 01937 |  Loss 0.6469\n",
      "Epoch 01938 |  Loss 0.6475\n",
      "Epoch 01939 |  Loss 0.6471\n",
      "Epoch 01940 |  Loss 0.6473\n",
      "Epoch 01941 |  Loss 0.6474\n",
      "Epoch 01942 |  Loss 0.6464\n",
      "Epoch 01943 |  Loss 0.6472\n",
      "Epoch 01944 |  Loss 0.6471\n",
      "Epoch 01945 |  Loss 0.6471\n",
      "Epoch 01946 |  Loss 0.6475\n",
      "Epoch 01947 |  Loss 0.6478\n",
      "Epoch 01948 |  Loss 0.6470\n",
      "Epoch 01949 |  Loss 0.6472\n",
      "Epoch 01950 |  Loss 0.6472\n",
      "Epoch 01951 |  Loss 0.6474\n",
      "Epoch 01952 |  Loss 0.6475\n",
      "Epoch 01953 |  Loss 0.6473\n",
      "Epoch 01954 |  Loss 0.6475\n",
      "Epoch 01955 |  Loss 0.6472\n",
      "Epoch 01956 |  Loss 0.6470\n",
      "Epoch 01957 |  Loss 0.6477\n",
      "Epoch 01958 |  Loss 0.6470\n",
      "Epoch 01959 |  Loss 0.6470\n",
      "Epoch 01960 |  Loss 0.6470\n",
      "Epoch 01961 |  Loss 0.6476\n",
      "Epoch 01962 |  Loss 0.6473\n",
      "Epoch 01963 |  Loss 0.6478\n",
      "Epoch 01964 |  Loss 0.6473\n",
      "Epoch 01965 |  Loss 0.6470\n",
      "Epoch 01966 |  Loss 0.6469\n",
      "Epoch 01967 |  Loss 0.6469\n",
      "Epoch 01968 |  Loss 0.6471\n",
      "Epoch 01969 |  Loss 0.6469\n",
      "Epoch 01970 |  Loss 0.6472\n",
      "Epoch 01971 |  Loss 0.6472\n",
      "Epoch 01972 |  Loss 0.6477\n",
      "Epoch 01973 |  Loss 0.6470\n",
      "Epoch 01974 |  Loss 0.6466\n",
      "Epoch 01975 |  Loss 0.6473\n",
      "Epoch 01976 |  Loss 0.6475\n",
      "Epoch 01977 |  Loss 0.6474\n",
      "Epoch 01978 |  Loss 0.6474\n",
      "Epoch 01979 |  Loss 0.6473\n",
      "Epoch 01980 |  Loss 0.6469\n",
      "Epoch 01981 |  Loss 0.6473\n",
      "Epoch 01982 |  Loss 0.6470\n",
      "Epoch 01983 |  Loss 0.6468\n",
      "Epoch 01984 |  Loss 0.6469\n",
      "Epoch 01985 |  Loss 0.6475\n",
      "Epoch 01986 |  Loss 0.6469\n",
      "Epoch 01987 |  Loss 0.6477\n",
      "Epoch 01988 |  Loss 0.6476\n",
      "Epoch 01989 |  Loss 0.6472\n",
      "Epoch 01990 |  Loss 0.6475\n",
      "Epoch 01991 |  Loss 0.6475\n",
      "Epoch 01992 |  Loss 0.6466\n",
      "Epoch 01993 |  Loss 0.6468\n",
      "No improvement found during the 50 last iterations, stopping optimization.\n"
     ]
    }
   ],
   "source": [
    "num_negs = 1\n",
    "neg_share = False\n",
    "device = th.device('cpu')\n",
    "num_hidden = 256\n",
    "num_layers = 2\n",
    "dropout = 0.25\n",
    "lr = 0.0001\n",
    "num_epochs = 10000\n",
    "best_loss = 1000000 \n",
    "last_improvement = 0\n",
    "require_improvements = 50\n",
    "best_state = None\n",
    "\n",
    "nfeat = g.ndata['feat'].float().to(device)\n",
    "# nfeat = build_nfeat_from_okved_data(okved_data).to(device)\n",
    "in_feats = nfeat.shape[1]\n",
    "n_edges = g.num_edges()\n",
    "\n",
    "\n",
    "model = Sage(in_feats, num_hidden, num_hidden, num_layers, F.relu, dropout)\n",
    "model = model.to(device)\n",
    "sampler = NegativeSampler(g, num_negs, neg_share, device)\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    neg_graph = sampler(clf_graph).to(device)\n",
    "    # Compute loss and prediction\n",
    "    pred = model(clf_graph, nfeat)\n",
    "    loss = criterion(pred, clf_graph, neg_graph)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f'Epoch {epoch:05d} |  Loss {loss.item():.4f}')\n",
    "\n",
    "    if loss.item() < best_loss:\n",
    "        best_loss = loss.item()\n",
    "        last_improvement = 0\n",
    "        best_state = model.state_dict()\n",
    "    else:\n",
    "        last_improvement += 1\n",
    "    if last_improvement > require_improvements:\n",
    "        print(f\"No improvement found during the {require_improvements} last iterations, stopping optimization.\")\n",
    "        model.load_state_dict(best_state)\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=2637, num_edges=438730,\n",
       "      ndata_schemes={}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1266, -0.0913, -0.1717,  ..., -0.2550, -0.1028, -0.0374],\n",
       "        [ 0.0236,  0.0076,  0.0754,  ..., -0.1338, -0.1767, -0.0850],\n",
       "        [ 0.1176, -0.1793, -0.0510,  ..., -0.1772,  0.0130,  0.0804],\n",
       "        ...,\n",
       "        [ 0.0239, -0.1121, -0.0222,  ..., -0.0029, -0.0696, -0.0118],\n",
       "        [ 0.2438,  0.2699, -0.0350,  ..., -0.0766, -0.2062,  0.2366],\n",
       "        [ 0.0999, -0.1860,  0.1036,  ..., -0.1389, -0.0271,  0.1005]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "embeddings_model = model(clf_graph, nfeat).detach().numpy()[1:]\n",
    "embeddings_model_2d = TSNE(n_components=2).fit_transform(embeddings_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_bert = np.load('../data/okved2/okved_embeddings.npy')\n",
    "embeddings_bert_2d = TSNE(n_components=2).fit_transform(embeddings_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.scatter(embeddings_bert_2d[:, 0], embeddings_bert_2d[:, 1], c=sections)\n",
    "ax.set_title('TSNE of BERT embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.scatter(embeddings_model_2d[:sections.shape[0], 0], embeddings_model_2d[:sections.shape[0], 1], c=sections)\n",
    "ax.set_title('TSNE of SAGE (only clf edges) embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "okved_embeddings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
